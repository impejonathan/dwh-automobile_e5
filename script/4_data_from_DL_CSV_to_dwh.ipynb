{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f4e72e7f",
   "metadata": {},
   "source": [
    "Cellule 1 : Imports et configuration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7698ad79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "üöÄ ETL DATA LAKE CSV ‚Üí DWH\n",
      "======================================================================\n",
      "üìÖ Date d'ex√©cution : 2026-02-09 19:37:13\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Imports r√©ussis\n",
      "‚úÖ Variables d'environnement charg√©es\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# ETL : DATA LAKE (CSV) ‚Üí DWH\n",
    "# Tables : DIM_GEOGRAPHIE, DIM_BORNE_RECHARGE\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import pyodbc\n",
    "from azure.storage.blob import BlobServiceClient\n",
    "from dotenv import load_dotenv\n",
    "from datetime import datetime\n",
    "from tqdm import tqdm\n",
    "import io\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"üöÄ ETL DATA LAKE CSV ‚Üí DWH\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"üìÖ Date d'ex√©cution : {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Charger les variables d'environnement\n",
    "load_dotenv()\n",
    "\n",
    "print(\"\\n‚úÖ Imports r√©ussis\")\n",
    "print(\"‚úÖ Variables d'environnement charg√©es\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "edbc6914",
   "metadata": {},
   "source": [
    "Cellule 2 : Configuration des connexions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eb2f51cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîß CONFIGURATION DES CONNEXIONS\n",
      "======================================================================\n",
      "‚úÖ Storage Account : datalakecertifimpe\n",
      "‚úÖ Conteneur Bronze : bronze-data\n",
      "‚úÖ Conteneur Gold : data-gouv\n",
      "‚úÖ Serveur DWH : carter-cash-serveur-student.database.windows.net\n",
      "‚úÖ Base DWH : DWH_E5_projet_AUTO\n",
      "‚úÖ D√©partements HDF : 59, 62, 80, 60, 02\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîß CONFIGURATION DES CONNEXIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ========================================\n",
    "# Configuration Azure Data Lake\n",
    "# ========================================\n",
    "STORAGE_ACCOUNT_NAME = os.getenv(\"STORAGE_ACCOUNT_NAME\")\n",
    "STORAGE_ACCOUNT_KEY = os.getenv(\"STORAGE_ACCOUNT_KEY\")\n",
    "CONTAINER_BRONZE = os.getenv(\"CONTAINER_BRONZE\")\n",
    "CONTAINER_GOLD = os.getenv(\"CONTAINER_GOLD\")\n",
    "\n",
    "# ========================================\n",
    "# Configuration DWH\n",
    "# ========================================\n",
    "DB_SERVER_DWH = os.getenv(\"DB_SERVER_DWH\")\n",
    "DB_DATABASE_DWH = os.getenv(\"DB_DATABASE_DWH\")\n",
    "DB_USERNAME_DWH = os.getenv(\"DB_USERNAME_DWH\")\n",
    "DB_PASSWORD_DWH = os.getenv(\"DB_PASSWORD_DWH\")\n",
    "\n",
    "# ========================================\n",
    "# Chemins des fichiers dans le Data Lake\n",
    "# ========================================\n",
    "FICHIER_BORNES = \"bornes-irve/2025/01/bornes_irve_hdf_20250131.csv\"\n",
    "FICHIER_COMMUNES = \"data_to_BDD_data_gouv_city_france/communes_france_2025/communes_france_2025_20251031.csv\"\n",
    "\n",
    "# ========================================\n",
    "# D√©partements Hauts-de-France √† filtrer\n",
    "# ========================================\n",
    "DEPARTEMENTS_HDF = ['59', '62', '80', '60' , '02']\n",
    "\n",
    "print(f\"‚úÖ Storage Account : {STORAGE_ACCOUNT_NAME}\")\n",
    "print(f\"‚úÖ Conteneur Bronze : {CONTAINER_BRONZE}\")\n",
    "print(f\"‚úÖ Conteneur Gold : {CONTAINER_GOLD}\")\n",
    "print(f\"‚úÖ Serveur DWH : {DB_SERVER_DWH}\")\n",
    "print(f\"‚úÖ Base DWH : {DB_DATABASE_DWH}\")\n",
    "print(f\"‚úÖ D√©partements HDF : {', '.join(DEPARTEMENTS_HDF)}\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79644873",
   "metadata": {},
   "source": [
    "Cellule 3 : Connexion √† Azure Data Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05861563",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîå CONNEXION √Ä AZURE DATA LAKE\n",
      "======================================================================\n",
      "‚ùå ERREUR de connexion au Data Lake : The specified account is disabled.\n",
      "RequestId:71802d63-301e-008c-04f3-99dadc000000\n",
      "Time:2026-02-09T18:38:13.9576215Z\n",
      "ErrorCode:AccountIsDisabled\n",
      "Content: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AccountIsDisabled</Code><Message>The specified account is disabled.\n",
      "RequestId:71802d63-301e-008c-04f3-99dadc000000\n",
      "Time:2026-02-09T18:38:13.9576215Z</Message></Error>\n"
     ]
    },
    {
     "ename": "HttpResponseError",
     "evalue": "The specified account is disabled.\nRequestId:71802d63-301e-008c-04f3-99dadc000000\nTime:2026-02-09T18:38:13.9576215Z\nErrorCode:AccountIsDisabled\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AccountIsDisabled</Code><Message>The specified account is disabled.\nRequestId:71802d63-301e-008c-04f3-99dadc000000\nTime:2026-02-09T18:38:13.9576215Z</Message></Error>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mHttpResponseError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m blob_service_client \u001b[38;5;241m=\u001b[39m BlobServiceClient\u001b[38;5;241m.\u001b[39mfrom_connection_string(connection_string)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# Tester la connexion\u001b[39;00m\n\u001b[1;32m---> 12\u001b[0m \u001b[43mblob_service_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_service_properties\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m‚úÖ Connexion r√©ussie √† Azure Data Lake\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Lister les conteneurs\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\azure\\core\\tracing\\decorator.py:119\u001b[0m, in \u001b[0;36mdistributed_trace.<locals>.decorator.<locals>.wrapper_use_tracer\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;66;03m# If tracing is disabled globally and user didn't explicitly enable it, don't trace.\u001b[39;00m\n\u001b[0;32m    118\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (\u001b[38;5;129;01mnot\u001b[39;00m tracing_enabled \u001b[38;5;129;01mand\u001b[39;00m user_enabled \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m    121\u001b[0m \u001b[38;5;66;03m# Merge span is parameter is set, but only if no explicit parent are passed\u001b[39;00m\n\u001b[0;32m    122\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m merge_span \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m passed_in_parent:\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\azure\\storage\\blob\\_blob_service_client.py:359\u001b[0m, in \u001b[0;36mBlobServiceClient.get_service_properties\u001b[1;34m(self, **kwargs)\u001b[0m\n\u001b[0;32m    357\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m service_properties_deserialize(service_props)\n\u001b[0;32m    358\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m HttpResponseError \u001b[38;5;28;01mas\u001b[39;00m error:\n\u001b[1;32m--> 359\u001b[0m     \u001b[43mprocess_storage_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Python310\\lib\\site-packages\\azure\\storage\\blob\\_shared\\response_handlers.py:195\u001b[0m, in \u001b[0;36mprocess_storage_error\u001b[1;34m(storage_error)\u001b[0m\n\u001b[0;32m    192\u001b[0m error\u001b[38;5;241m.\u001b[39margs \u001b[38;5;241m=\u001b[39m (error\u001b[38;5;241m.\u001b[39mmessage,)\n\u001b[0;32m    193\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    194\u001b[0m     \u001b[38;5;66;03m# `from None` prevents us from double printing the exception (suppresses generated layer error context)\u001b[39;00m\n\u001b[1;32m--> 195\u001b[0m     \u001b[43mexec\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mraise error from None\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# pylint: disable=exec-used # nosec\u001b[39;00m\n\u001b[0;32m    196\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mSyntaxError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    197\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m error \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "File \u001b[1;32m<string>:1\u001b[0m\n",
      "\u001b[1;31mHttpResponseError\u001b[0m: The specified account is disabled.\nRequestId:71802d63-301e-008c-04f3-99dadc000000\nTime:2026-02-09T18:38:13.9576215Z\nErrorCode:AccountIsDisabled\nContent: <?xml version=\"1.0\" encoding=\"utf-8\"?><Error><Code>AccountIsDisabled</Code><Message>The specified account is disabled.\nRequestId:71802d63-301e-008c-04f3-99dadc000000\nTime:2026-02-09T18:38:13.9576215Z</Message></Error>"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîå CONNEXION √Ä AZURE DATA LAKE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Cr√©er la cha√Æne de connexion\n",
    "    connection_string = f\"DefaultEndpointsProtocol=https;AccountName={STORAGE_ACCOUNT_NAME};AccountKey={STORAGE_ACCOUNT_KEY};EndpointSuffix=core.windows.net\"\n",
    "    \n",
    "    # Cr√©er le client Blob Service\n",
    "    blob_service_client = BlobServiceClient.from_connection_string(connection_string)\n",
    "    \n",
    "    # Tester la connexion\n",
    "    blob_service_client.get_service_properties()\n",
    "    \n",
    "    print(\"‚úÖ Connexion r√©ussie √† Azure Data Lake\")\n",
    "    \n",
    "    # Lister les conteneurs\n",
    "    containers = [container.name for container in blob_service_client.list_containers()]\n",
    "    print(f\"üì¶ Conteneurs disponibles : {', '.join(containers)}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERREUR de connexion au Data Lake : {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95024939",
   "metadata": {},
   "source": [
    "Cellule 4 : Connexion au DWH\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "6b99deba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîå CONNEXION AU DATA WAREHOUSE\n",
      "======================================================================\n",
      "‚úÖ Connexion r√©ussie au DWH\n",
      "üìä Base de donn√©es : DWH_E5_projet_AUTO\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîå CONNEXION AU DATA WAREHOUSE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "try:\n",
    "    # Cha√Æne de connexion SQL Server\n",
    "    connection_string_dwh = (\n",
    "        f\"DRIVER={{ODBC Driver 18 for SQL Server}};\"\n",
    "        f\"SERVER={DB_SERVER_DWH};\"\n",
    "        f\"DATABASE={DB_DATABASE_DWH};\"\n",
    "        f\"UID={DB_USERNAME_DWH};\"\n",
    "        f\"PWD={DB_PASSWORD_DWH};\"\n",
    "        f\"Encrypt=yes;\"\n",
    "        f\"TrustServerCertificate=no;\"\n",
    "        f\"Connection Timeout=30;\"\n",
    "    )\n",
    "    \n",
    "    cnxn_dwh = pyodbc.connect(connection_string_dwh)\n",
    "    cursor_dwh = cnxn_dwh.cursor()\n",
    "    \n",
    "    # Test de connexion\n",
    "    cursor_dwh.execute(\"SELECT @@VERSION\")\n",
    "    version = cursor_dwh.fetchone()[0]\n",
    "    \n",
    "    print(\"‚úÖ Connexion r√©ussie au DWH\")\n",
    "    print(f\"üìä Base de donn√©es : {DB_DATABASE_DWH}\")\n",
    "    \n",
    "except Exception as e:\n",
    "    print(f\"‚ùå ERREUR de connexion au DWH : {e}\")\n",
    "    raise\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2faafee",
   "metadata": {},
   "source": [
    "Cellule 5 : Fonction de lecture CSV depuis Data Lake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "0df91c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì¶ FONCTIONS UTILITAIRES\n",
      "======================================================================\n",
      "‚úÖ Fonctions utilitaires d√©finies\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüì¶ FONCTIONS UTILITAIRES\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "def lire_csv_depuis_datalake(container_name, blob_path, separator=';', encoding='utf-8'):\n",
    "    \"\"\"\n",
    "    Lit un fichier CSV depuis Azure Data Lake et retourne un DataFrame pandas\n",
    "    \n",
    "    Args:\n",
    "        container_name: Nom du conteneur\n",
    "        blob_path: Chemin du fichier dans le conteneur\n",
    "        separator: S√©parateur CSV (par d√©faut ';')\n",
    "        encoding: Encodage du fichier (par d√©faut 'utf-8')\n",
    "    \n",
    "    Returns:\n",
    "        DataFrame pandas\n",
    "    \"\"\"\n",
    "    try:\n",
    "        print(f\"‚è≥ Lecture de {blob_path}...\")\n",
    "        \n",
    "        # Obtenir le client du conteneur\n",
    "        container_client = blob_service_client.get_container_client(container_name)\n",
    "        \n",
    "        # T√©l√©charger le blob\n",
    "        blob_client = container_client.get_blob_client(blob_path)\n",
    "        blob_data = blob_client.download_blob()\n",
    "        \n",
    "        # Lire le contenu en m√©moire\n",
    "        content = blob_data.readall()\n",
    "        \n",
    "        # Convertir en DataFrame\n",
    "        df = pd.read_csv(io.BytesIO(content), sep=separator, encoding=encoding, low_memory=False)\n",
    "        \n",
    "        print(f\"‚úÖ Fichier charg√© : {len(df)} lignes, {len(df.columns)} colonnes\")\n",
    "        \n",
    "        return df\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå ERREUR lors de la lecture du fichier {blob_path} : {e}\")\n",
    "        raise\n",
    "\n",
    "print(\"‚úÖ Fonctions utilitaires d√©finies\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2e4863",
   "metadata": {},
   "source": [
    "Cellule 6 : Chargement des fichiers CSV\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "3746a3ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• CHARGEMENT DES FICHIERS CSV DEPUIS DATA LAKE\n",
      "======================================================================\n",
      "\n",
      "1Ô∏è‚É£  Chargement du fichier BORNES IRVE...\n",
      "‚è≥ Lecture de bornes-irve/2025/01/bornes_irve_hdf_20250131.csv...\n",
      "‚úÖ Fichier charg√© : 1666 lignes, 22 colonnes\n",
      "   Colonnes : ['n_amenageur', 'n_operateur', 'n_enseigne', 'id_station', 'n_station', 'ad_station', 'code_insee', 'Xlongitude', 'Ylatitude', 'nbre_pdc']...\n",
      "   Premi√®res lignes :\n",
      "                                         n_amenageur  \\\n",
      "0  Communaut√© d'Agglom√©ration Maubeuge Val de Sambre   \n",
      "1  Communaut√© d'Agglom√©ration Maubeuge Val de Sambre   \n",
      "\n",
      "                     n_operateur            n_enseigne         id_station  \\\n",
      "0  BOUYGUES ENERGIES ET SERVICES  pass pass √©lectrique  FR*H02*P59101*001   \n",
      "1  BOUYGUES ENERGIES ET SERVICES  pass pass √©lectrique  FR*H02*P59543*001   \n",
      "\n",
      "                              n_station  \\\n",
      "0      BOUSIGNIES-SUR-ROC - Grand Place   \n",
      "1  SAINT-R√âMY-DU-NORD - Rue de la Place   \n",
      "\n",
      "                                 ad_station  code_insee  Xlongitude  \\\n",
      "0      Grand Place 59149 BOUSIGNIES-SUR-ROC     59101.0    4.181942   \n",
      "1  Rue de la Place 59330 SAINT-R√âMY-DU-NORD     59543.0    3.905528   \n",
      "\n",
      "   Ylatitude  nbre_pdc  ... type_prise  acces_recharge accessibilit√©  \\\n",
      "0  50.264118         2  ...    EF - T2          payant   24h/24 7j/7   \n",
      "1  50.231396         2  ...    EF - T2          payant   24h/24 7j/7   \n",
      "\n",
      "                                        observations    date_maj  \\\n",
      "0  Recharge par badge et avec une application sma...  2020-04-03   \n",
      "1  Recharge par badge et avec une application sma...  2020-04-03   \n",
      "\n",
      "                                              source      geo_point_borne  \\\n",
      "0  https://www.data.gouv.fr/fr/datasets/infrastru...  50.264118, 4.181942   \n",
      "1  https://www.data.gouv.fr/fr/datasets/infrastru...  50.231396, 3.905528   \n",
      "\n",
      "  code_insee_commune           R√©gion  departement  \n",
      "0              59101  Hauts-de-France         Nord  \n",
      "1              59543  Hauts-de-France         Nord  \n",
      "\n",
      "[2 rows x 22 columns]\n",
      "\n",
      "2Ô∏è‚É£  Chargement du fichier COMMUNES...\n",
      "‚è≥ Lecture de data_to_BDD_data_gouv_city_france/communes_france_2025/communes_france_2025_20251031.csv...\n",
      "‚úÖ Fichier charg√© : 34935 lignes, 47 colonnes\n",
      "   Colonnes : ['Unnamed: 0', 'code_insee', 'nom_standard', 'nom_sans_pronom', 'nom_a', 'nom_de', 'nom_sans_accent', 'nom_standard_majuscule', 'typecom', 'typecom_texte']...\n",
      "   Premi√®res lignes :\n",
      "   Unnamed: 0 code_insee             nom_standard        nom_sans_pronom  \\\n",
      "0           0      01001  L'Abergement-Cl√©menciat  Abergement-Cl√©menciat   \n",
      "1           1      01002    L'Abergement-de-Varey    Abergement-de-Varey   \n",
      "\n",
      "                     nom_a                      nom_de  \\\n",
      "0  √† Abergement-Cl√©menciat  de l'Abergement-Cl√©menciat   \n",
      "1    √† Abergement-de-Varey    de l'Abergement-de-Varey   \n",
      "\n",
      "           nom_sans_accent   nom_standard_majuscule typecom typecom_texte  \\\n",
      "0  l-abergement-clemenciat  L'ABERGEMENT-CL√âMENCIAT     COM       commune   \n",
      "1    l-abergement-de-varey    L'ABERGEMENT-DE-VAREY     COM       commune   \n",
      "\n",
      "   ...  longitude_mairie latitude_centre longitude_centre grille_densite  \\\n",
      "0  ...             4.921          46.153            4.926              6   \n",
      "1  ...             5.423          46.009            5.428              6   \n",
      "\n",
      "       grille_densite_texte niveau_equipements_services  \\\n",
      "0  Rural √† habitat dispers√©                         0.0   \n",
      "1  Rural √† habitat dispers√©                         0.0   \n",
      "\n",
      "  niveau_equipements_services_texte                         gentile  \\\n",
      "0                 communes non p√¥le                             NaN   \n",
      "1                 communes non p√¥le  Abergementais, Abergementaises   \n",
      "\n",
      "                                       url_wikipedia  \\\n",
      "0  https://fr.wikipedia.org/wiki/fr:L'Abergement-...   \n",
      "1  https://fr.wikipedia.org/wiki/fr:L'Abergement-...   \n",
      "\n",
      "                                     url_villedereve  \n",
      "0  https://villedereve.fr/ville/01001-l-abergemen...  \n",
      "1  https://villedereve.fr/ville/01002-l-abergemen...  \n",
      "\n",
      "[2 rows x 47 columns]\n",
      "\n",
      "‚úÖ Tous les fichiers CSV charg√©s avec succ√®s\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüì• CHARGEMENT DES FICHIERS CSV DEPUIS DATA LAKE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ========================================\n",
    "# 1. Charger le fichier des bornes IRVE\n",
    "# ========================================\n",
    "print(\"\\n1Ô∏è‚É£  Chargement du fichier BORNES IRVE...\")\n",
    "df_bornes = lire_csv_depuis_datalake(CONTAINER_BRONZE, FICHIER_BORNES, separator=';', encoding='utf-8')\n",
    "\n",
    "print(f\"   Colonnes : {list(df_bornes.columns[:10])}...\")\n",
    "print(f\"   Premi√®res lignes :\")\n",
    "print(df_bornes.head(2))\n",
    "\n",
    "# ========================================\n",
    "# 2. Charger le fichier des communes\n",
    "# ========================================\n",
    "print(\"\\n2Ô∏è‚É£  Chargement du fichier COMMUNES...\")\n",
    "df_communes = lire_csv_depuis_datalake(CONTAINER_GOLD, FICHIER_COMMUNES, separator=',', encoding='utf-8')\n",
    "\n",
    "print(f\"   Colonnes : {list(df_communes.columns[:10])}...\")\n",
    "print(f\"   Premi√®res lignes :\")\n",
    "print(df_communes.head(2))\n",
    "\n",
    "print(\"\\n‚úÖ Tous les fichiers CSV charg√©s avec succ√®s\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cb2ff1",
   "metadata": {},
   "source": [
    "Cellule 7 : ETL - Chargement de DIM_GEOGRAPHIE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "573320f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• ETL - CHARGEMENT DE DIM_GEOGRAPHIE\n",
      "======================================================================\n",
      "\n",
      "‚è≥ Filtrage des communes des Hauts-de-France (59, 62, 80, 60, 02)...\n",
      "‚úÖ 3788 communes trouv√©es dans les Hauts-de-France\n",
      "\n",
      "‚è≥ Pr√©paration des donn√©es g√©ographiques...\n",
      "‚úÖ 3788 g√©ographies uniques (Code_INSEE) √† charger\n",
      "\n",
      "‚è≥ Chargement des g√©ographies d√©j√† pr√©sentes dans le DWH...\n",
      "‚úÖ 3788 g√©ographies d√©j√† pr√©sentes dans DIM_GEOGRAPHIE\n",
      "‚úÖ 0 nouvelles g√©ographies √† ins√©rer\n",
      "‚úÖ Aucune nouvelle g√©ographie √† ins√©rer\n",
      "\n",
      "üßπ Nettoyage des doublons dans DIM_GEOGRAPHIE...\n",
      "‚úÖ Aucun doublon d√©tect√©.\n",
      "\n",
      "üìä Total final dans DIM_GEOGRAPHIE : 3788\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\nüì• ETL - CHARGEMENT DE DIM_GEOGRAPHIE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ========================================\n",
    "# FILTRER UNIQUEMENT LES D√âPARTEMENTS HDF (59, 62, 80)\n",
    "# ========================================\n",
    "print(f\"\\n‚è≥ Filtrage des communes des Hauts-de-France ({', '.join(DEPARTEMENTS_HDF)})...\")\n",
    "\n",
    "df_communes_hdf = df_communes[df_communes['dep_code'].astype(str).isin(DEPARTEMENTS_HDF)].copy()\n",
    "print(f\"‚úÖ {len(df_communes_hdf)} communes trouv√©es dans les Hauts-de-France\")\n",
    "\n",
    "# ========================================\n",
    "# PR√âPARATION DES DONN√âES GEOGRAPHIQUES\n",
    "# ========================================\n",
    "print(\"\\n‚è≥ Pr√©paration des donn√©es g√©ographiques...\")\n",
    "\n",
    "# S√©lectionner et renommer les colonnes n√©cessaires selon votre sch√©ma de DWH\n",
    "geo_data = df_communes_hdf[[\n",
    "    'code_insee',\n",
    "    'nom_standard',\n",
    "    'code_postal',\n",
    "    'reg_code',\n",
    "    'reg_nom',\n",
    "    'dep_code',\n",
    "    'dep_nom',\n",
    "    'population',\n",
    "    'superficie_km2',\n",
    "    'densite',\n",
    "    'latitude_mairie',\n",
    "    'longitude_mairie'\n",
    "]].copy()\n",
    "\n",
    "geo_data.columns = [\n",
    "    'Code_INSEE',\n",
    "    'Nom_Commune',\n",
    "    'Code_Postal',\n",
    "    'Reg_Code',\n",
    "    'Reg_Nom',\n",
    "    'Dep_Code',\n",
    "    'Dep_Nom',\n",
    "    'Population',\n",
    "    'Superficie_km2',\n",
    "    'Densite',\n",
    "    'Latitude',\n",
    "    'Longitude'\n",
    "]\n",
    "\n",
    "# Remplacer les NaN pour √©viter les soucis √† l'insertion\n",
    "geo_data = geo_data.fillna({'Code_Postal': '00000', 'Population': 0, 'Superficie_km2': 0.0, 'Densite': 0.0, 'Latitude': 0.0, 'Longitude': 0.0})\n",
    "geo_data['Population'] = geo_data['Population'].astype(int)\n",
    "\n",
    "# Supprimer les doublons √©ventuels sur Code_INSEE\n",
    "geo_data = geo_data.drop_duplicates(subset=['Code_INSEE'])\n",
    "\n",
    "print(f\"‚úÖ {len(geo_data)} g√©ographies uniques (Code_INSEE) √† charger\")\n",
    "\n",
    "# ========================================\n",
    "# CHARGER LES CODE_INSEE EXISTANTS\n",
    "# ========================================\n",
    "print(\"\\n‚è≥ Chargement des g√©ographies d√©j√† pr√©sentes dans le DWH...\")\n",
    "cursor_dwh.execute(\"SELECT Code_INSEE FROM DIM_GEOGRAPHIE\")\n",
    "geo_existantes = set(row[0] for row in cursor_dwh.fetchall())\n",
    "print(f\"‚úÖ {len(geo_existantes)} g√©ographies d√©j√† pr√©sentes dans DIM_GEOGRAPHIE\")\n",
    "\n",
    "# ========================================\n",
    "# FILTRER LES NOUVELLES GEOGRAPHIES\n",
    "# ========================================\n",
    "geo_nouvelles = geo_data[~geo_data['Code_INSEE'].isin(geo_existantes)]\n",
    "print(f\"‚úÖ {len(geo_nouvelles)} nouvelles g√©ographies √† ins√©rer\")\n",
    "\n",
    "# ========================================\n",
    "# INSERTION PAR BATCH (pour efficacit√©)\n",
    "# ========================================\n",
    "if len(geo_nouvelles) > 0:\n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO DIM_GEOGRAPHIE (\n",
    "        Code_INSEE, Nom_Commune, Code_Postal, Reg_Code, Reg_Nom,\n",
    "        Dep_Code, Dep_Nom, Population, Superficie_km2, Densite,\n",
    "        Latitude, Longitude\n",
    "    ) VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    batch_size = 300\n",
    "    total_insert = 0\n",
    "    tuples = [tuple(x) for x in geo_nouvelles.values]\n",
    "    for i in tqdm(range(0, len(tuples), batch_size), desc=\"Insertion g√©ographies\", unit=\"batch\"):\n",
    "        batch = tuples[i:i+batch_size]\n",
    "        try:\n",
    "            cursor_dwh.executemany(insert_query, batch)\n",
    "            cnxn_dwh.commit()\n",
    "            total_insert += len(batch)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ö†Ô∏è Erreur batch {i//batch_size+1}: {e}\")\n",
    "            for row in batch:\n",
    "                try:\n",
    "                    cursor_dwh.execute(insert_query, row)\n",
    "                    total_insert += 1\n",
    "                except:\n",
    "                    pass\n",
    "            cnxn_dwh.commit()\n",
    "    print(f\"\\n‚úÖ {total_insert} lignes ins√©r√©es dans DIM_GEOGRAPHIE\")\n",
    "else:\n",
    "    print(\"‚úÖ Aucune nouvelle g√©ographie √† ins√©rer\")\n",
    "\n",
    "# ========================================\n",
    "# NETTOYAGE DES DOUBLONS\n",
    "# ========================================\n",
    "print(\"\\nüßπ Nettoyage des doublons dans DIM_GEOGRAPHIE...\")\n",
    "\n",
    "# D√©tecter les doublons par code INSEE (si jamais)\n",
    "cursor_dwh.execute(\"\"\"\n",
    "SELECT Code_INSEE, COUNT(*) AS nb\n",
    "FROM DIM_GEOGRAPHIE\n",
    "GROUP BY Code_INSEE\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\")\n",
    "doublons = cursor_dwh.fetchall()\n",
    "doublons_count = sum([row[1]-1 for row in doublons])\n",
    "if doublons_count > 0:\n",
    "    print(f\"‚ö†Ô∏è {doublons_count} doublons trouv√©s, suppression...\")\n",
    "    for row in doublons:\n",
    "        code_insee = row[0]\n",
    "        cursor_dwh.execute(\"\"\"\n",
    "            DELETE FROM DIM_GEOGRAPHIE\n",
    "            WHERE Code_INSEE = ?\n",
    "            AND SK_Geographie NOT IN (\n",
    "                SELECT MIN(SK_Geographie)\n",
    "                FROM DIM_GEOGRAPHIE\n",
    "                WHERE Code_INSEE = ?\n",
    "            )\n",
    "        \"\"\", code_insee, code_insee)\n",
    "        cnxn_dwh.commit()\n",
    "    print(\"‚úÖ Doublons supprim√©s.\")\n",
    "else:\n",
    "    print(\"‚úÖ Aucun doublon d√©tect√©.\")\n",
    "\n",
    "# Validation finale\n",
    "cursor_dwh.execute(\"SELECT COUNT(*) FROM DIM_GEOGRAPHIE\")\n",
    "nb_final = cursor_dwh.fetchone()[0]\n",
    "print(f\"\\nüìä Total final dans DIM_GEOGRAPHIE : {nb_final}\")\n",
    "\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üì¶ Cellule 8 : ETL - Chargement de DIM_BORNE_RECHARGE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6dd24e49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• ETL - CHARGEMENT DE DIM_BORNE_RECHARGE\n",
      "======================================================================\n",
      "‚è≥ Pr√©paration des donn√©es des bornes...\n",
      "‚è≥ Nettoyage et conversion des donn√©es...\n",
      "‚è≥ Formatage des codes INSEE...\n",
      "‚úÖ Codes INSEE format√©s\n",
      "\n",
      "üìä Exemples de codes INSEE apr√®s formatage :\n",
      "['59101', '59543', '59392', '59225', '59324', '59365', '59514', '59231', '59230', '59406']\n",
      "\n",
      "‚úÖ 913 bornes uniques pr√©par√©es\n",
      "\n",
      "‚è≥ Chargement des bornes d√©j√† pr√©sentes dans le DWH...\n",
      "‚úÖ 913 bornes d√©j√† pr√©sentes dans le DWH\n",
      "\n",
      "‚è≥ Filtrage des nouvelles bornes √† ins√©rer...\n",
      "‚úÖ 0 nouvelles bornes √† ins√©rer\n",
      "‚ö†Ô∏è  913 bornes d√©j√† existantes (ignor√©es)\n",
      "\n",
      "‚úÖ Aucune nouvelle borne √† ins√©rer\n",
      "\n",
      "üßπ NETTOYAGE DES DOUBLONS\n",
      "======================================================================\n",
      "‚è≥ D√©tection des doublons...\n",
      "‚úÖ Aucun doublon trouv√© dans DIM_BORNE_RECHARGE\n",
      "\n",
      "üîç V√âRIFICATION FINALE\n",
      "======================================================================\n",
      "üìä Nombre total de bornes dans DIM_BORNE_RECHARGE : 913\n",
      "‚úÖ Aucun doublon d√©tect√© - Table propre !\n",
      "\n",
      "üìç R√©partition des bornes par d√©partement (code INSEE) :\n",
      "   ‚Ä¢ D√©partement 59 : 396 bornes - 1331 points de charge\n",
      "   ‚Ä¢ D√©partement 02 : 211 bornes - 420 points de charge\n",
      "   ‚Ä¢ D√©partement 62 : 185 bornes - 578 points de charge\n",
      "   ‚Ä¢ D√©partement 60 : 118 bornes - 244 points de charge\n",
      "   ‚Ä¢ D√©partement 80 : 3 bornes - 13 points de charge\n",
      "\n",
      "‚ö° Statistiques sur les points de charge (PDC) :\n",
      "   ‚Ä¢ Nombre total de stations : 913\n",
      "   ‚Ä¢ Total points de charge : 2586\n",
      "   ‚Ä¢ Moyenne PDC/station : 2.83\n",
      "   ‚Ä¢ Min PDC : 1\n",
      "   ‚Ä¢ Max PDC : 32\n",
      "\n",
      "üìç Exemples de bornes ins√©r√©es :\n",
      "   ‚Ä¢ Station: FR*M59*P59609*001 | VENDEVILLE - Rue de Seclin\n",
      "     Type: EF - T2 | Puissance: 18.00 kW | PDC: 2\n",
      "     Commune INSEE: 59609 | Coords: (3.080624, 50.576416)\n",
      "   ‚Ä¢ Station: FR*SOD*S*NPDC*234*1*_*_ | Vendeville - St Rita\n",
      "     Type: E/F-T2 | Puissance: 0.00 kW | PDC: 2\n",
      "     Commune INSEE: 59609 | Coords: (3.080624, 50.576415)\n",
      "   ‚Ä¢ Station: FR*S60*PJYVUUB | Chambly, Rue Raymond Joly\n",
      "     Type: T2 - E/F | Puissance: 22.00 kW | PDC: 2\n",
      "     Commune INSEE: 60139 | Coords: (2.25257, 49.1692)\n",
      "   ‚Ä¢ Station: FR*SSD*PLEMPEREURMAZDA59187*1 | Mazda Douai / Dechy\n",
      "     Type: EF, T2 | Puissance: 22.08 kW | PDC: 4\n",
      "     Commune INSEE: 59170 | Coords: (3.121247, 50.342806)\n",
      "   ‚Ä¢ Station: FR*SSD*PASLAREAENGLOS59320*1 | ASL AREA Englos\n",
      "     Type: T2 | Puissance: 22.08 kW | PDC: 2\n",
      "     Commune INSEE: 59195 | Coords: (2.96217, 50.624699)\n",
      "\n",
      "======================================================================\n",
      "‚úÖ CHARGEMENT TERMIN√â :\n",
      "   ‚Ä¢ 0 nouvelles bornes ins√©r√©es\n",
      "   ‚Ä¢ 913 bornes d√©j√† existantes (ignor√©es)\n",
      "   ‚Ä¢ 913 bornes uniques au total\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\nüì• ETL - CHARGEMENT DE DIM_BORNE_RECHARGE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ========================================\n",
    "# MAPPING DES COLONNES CSV ‚Üí DWH\n",
    "# ========================================\n",
    "print(\"‚è≥ Pr√©paration des donn√©es des bornes...\")\n",
    "\n",
    "# Renommer les colonnes du CSV pour correspondre au sch√©ma DWH\n",
    "colonnes_mapping = {\n",
    "    'id_station': 'ID_Station',\n",
    "    'n_station': 'Nom_Station',\n",
    "    'type_prise': 'Type_Prise',\n",
    "    'puiss_max': 'Puissance_kW',\n",
    "    'n_operateur': 'Operateur',\n",
    "    'acces_recharge': 'Acces',\n",
    "    'accessibilit√©': 'Statut',\n",
    "    'date_maj': 'Date_Mise_Service',\n",
    "    'code_insee_commune': 'code_insee_commune',\n",
    "    'Xlongitude': 'Xlongitude',\n",
    "    'Ylatitude': 'Ylatitude',\n",
    "    'nbre_pdc': 'nbre_pdc'  # üÜï NOUVELLE COLONNE\n",
    "}\n",
    "\n",
    "df_bornes_clean = df_bornes.rename(columns=colonnes_mapping)\n",
    "\n",
    "# S√©lectionner uniquement les colonnes n√©cessaires\n",
    "colonnes_dwh = [\n",
    "    'ID_Station',\n",
    "    'Nom_Station',\n",
    "    'Type_Prise',\n",
    "    'Puissance_kW',\n",
    "    'Operateur',\n",
    "    'Acces',\n",
    "    'Statut',\n",
    "    'Date_Mise_Service',\n",
    "    'code_insee_commune',\n",
    "    'Xlongitude',\n",
    "    'Ylatitude',\n",
    "    'nbre_pdc'  # üÜï NOUVELLE COLONNE\n",
    "]\n",
    "\n",
    "df_bornes_clean = df_bornes_clean[colonnes_dwh].copy()\n",
    "\n",
    "# ========================================\n",
    "# NETTOYAGE ET CONVERSION DES TYPES\n",
    "# ========================================\n",
    "print(\"‚è≥ Nettoyage et conversion des donn√©es...\")\n",
    "\n",
    "# Conversion de la puissance en num√©rique\n",
    "df_bornes_clean['Puissance_kW'] = pd.to_numeric(df_bornes_clean['Puissance_kW'], errors='coerce').fillna(0.0)\n",
    "\n",
    "# üÜï Conversion du nombre de PDC en entier\n",
    "df_bornes_clean['nbre_pdc'] = pd.to_numeric(df_bornes_clean['nbre_pdc'], errors='coerce').fillna(0).astype(int)\n",
    "\n",
    "# Conversion de la date\n",
    "df_bornes_clean['Date_Mise_Service'] = pd.to_datetime(df_bornes_clean['Date_Mise_Service'], errors='coerce')\n",
    "\n",
    "# Nettoyage des valeurs NULL pour les champs obligatoires\n",
    "df_bornes_clean['ID_Station'] = df_bornes_clean['ID_Station'].fillna('STATION_INCONNUE')\n",
    "df_bornes_clean['Nom_Station'] = df_bornes_clean['Nom_Station'].fillna('Non renseign√©')\n",
    "df_bornes_clean['Type_Prise'] = df_bornes_clean['Type_Prise'].fillna('Type inconnu')\n",
    "df_bornes_clean['Operateur'] = df_bornes_clean['Operateur'].fillna('Op√©rateur inconnu')\n",
    "df_bornes_clean['Acces'] = df_bornes_clean['Acces'].fillna('Non renseign√©')\n",
    "df_bornes_clean['Statut'] = df_bornes_clean['Statut'].fillna('Non renseign√©')\n",
    "df_bornes_clean['Xlongitude'] = df_bornes_clean['Xlongitude'].astype(str).fillna('0.0')\n",
    "df_bornes_clean['Ylatitude'] = df_bornes_clean['Ylatitude'].astype(str).fillna('0.0')\n",
    "\n",
    "# ========================================\n",
    "# FORMATAGE DU CODE INSEE (PADDING √Ä 5 CHIFFRES)\n",
    "# ========================================\n",
    "print(\"‚è≥ Formatage des codes INSEE...\")\n",
    "\n",
    "# Convertir en string et nettoyer\n",
    "df_bornes_clean['code_insee_commune'] = df_bornes_clean['code_insee_commune'].astype(str).str.strip()\n",
    "\n",
    "# Remplacer 'nan' ou valeurs vides par '00000'\n",
    "df_bornes_clean['code_insee_commune'] = df_bornes_clean['code_insee_commune'].replace(['nan', 'None', ''], '00000')\n",
    "\n",
    "# Ajouter un z√©ro devant si le code fait 4 chiffres (ex: 2563 -> 02563)\n",
    "def formater_code_insee(code):\n",
    "    \"\"\"Formate le code INSEE pour qu'il ait toujours 5 chiffres\"\"\"\n",
    "    code = str(code).strip()\n",
    "    \n",
    "    # Si c'est un code num√©rique\n",
    "    if code.isdigit():\n",
    "        # Padding avec des z√©ros √† gauche pour avoir 5 chiffres\n",
    "        return code.zfill(5)\n",
    "    else:\n",
    "        # Sinon, retourner tel quel ou code par d√©faut\n",
    "        return code if code != '' else '00000'\n",
    "\n",
    "df_bornes_clean['code_insee_commune'] = df_bornes_clean['code_insee_commune'].apply(formater_code_insee)\n",
    "\n",
    "print(f\"‚úÖ Codes INSEE format√©s\")\n",
    "print(f\"\\nüìä Exemples de codes INSEE apr√®s formatage :\")\n",
    "print(df_bornes_clean['code_insee_commune'].head(10).tolist())\n",
    "\n",
    "# Supprimer les doublons sur la combinaison ID_Station + Type_Prise + Puissance\n",
    "df_bornes_clean = df_bornes_clean.drop_duplicates(\n",
    "    subset=['ID_Station', 'Type_Prise', 'Puissance_kW']\n",
    ")\n",
    "\n",
    "print(f\"\\n‚úÖ {len(df_bornes_clean)} bornes uniques pr√©par√©es\")\n",
    "\n",
    "# ========================================\n",
    "# CHARGER LES BORNES EXISTANTES EN M√âMOIRE\n",
    "# ========================================\n",
    "print(\"\\n‚è≥ Chargement des bornes d√©j√† pr√©sentes dans le DWH...\")\n",
    "cursor_dwh.execute(\"\"\"\n",
    "SELECT ID_Station, Type_Prise, Puissance_kW\n",
    "FROM DIM_BORNE_RECHARGE\n",
    "\"\"\")\n",
    "\n",
    "bornes_existantes = set()\n",
    "for row in cursor_dwh.fetchall():\n",
    "    cle = (row[0], row[1], float(row[2]))\n",
    "    bornes_existantes.add(cle)\n",
    "\n",
    "print(f\"‚úÖ {len(bornes_existantes)} bornes d√©j√† pr√©sentes dans le DWH\")\n",
    "\n",
    "# ========================================\n",
    "# FILTRER LES NOUVELLES BORNES √Ä INS√âRER\n",
    "# ========================================\n",
    "print(\"\\n‚è≥ Filtrage des nouvelles bornes √† ins√©rer...\")\n",
    "nouvelles_bornes = []\n",
    "\n",
    "for idx, row in df_bornes_clean.iterrows():\n",
    "    cle = (row['ID_Station'], row['Type_Prise'], float(row['Puissance_kW']))\n",
    "    \n",
    "    if cle not in bornes_existantes:\n",
    "        nouvelles_bornes.append((\n",
    "            row['ID_Station'],\n",
    "            row['Nom_Station'],\n",
    "            row['Type_Prise'],\n",
    "            float(row['Puissance_kW']),\n",
    "            row['Operateur'],\n",
    "            row['Acces'],\n",
    "            row['Statut'],\n",
    "            row['Date_Mise_Service'],\n",
    "            row['code_insee_commune'],  # Format√© √† 5 chiffres\n",
    "            row['Xlongitude'],\n",
    "            row['Ylatitude'],\n",
    "            int(row['nbre_pdc'])  # üÜï NOUVELLE COLONNE\n",
    "        ))\n",
    "\n",
    "skip_count = len(df_bornes_clean) - len(nouvelles_bornes)\n",
    "print(f\"‚úÖ {len(nouvelles_bornes)} nouvelles bornes √† ins√©rer\")\n",
    "print(f\"‚ö†Ô∏è  {skip_count} bornes d√©j√† existantes (ignor√©es)\")\n",
    "\n",
    "# ========================================\n",
    "# INSERTION PAR BATCH\n",
    "# ========================================\n",
    "if len(nouvelles_bornes) > 0:\n",
    "    print(\"\\n‚è≥ Insertion des nouvelles bornes...\")\n",
    "    \n",
    "    insert_query = \"\"\"\n",
    "    INSERT INTO DIM_BORNE_RECHARGE (\n",
    "        ID_Station, Nom_Station, Type_Prise, Puissance_kW,\n",
    "        Operateur, Acces, Statut, Date_Mise_Service,\n",
    "        code_insee_commune, Xlongitude, Ylatitude, nbre_pdc\n",
    "    )\n",
    "    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?, ?)\n",
    "    \"\"\"\n",
    "    \n",
    "    batch_size = 500\n",
    "    insert_count = 0\n",
    "    \n",
    "    for i in tqdm(range(0, len(nouvelles_bornes), batch_size), desc=\"Insertion bornes\", unit=\"batch\"):\n",
    "        batch = nouvelles_bornes[i:i+batch_size]\n",
    "        \n",
    "        try:\n",
    "            cursor_dwh.executemany(insert_query, batch)\n",
    "            cnxn_dwh.commit()\n",
    "            insert_count += len(batch)\n",
    "        except Exception as e:\n",
    "            print(f\"\\n‚ö†Ô∏è  Erreur lors de l'insertion du batch {i//batch_size + 1} : {e}\")\n",
    "            # En cas d'erreur, ins√©rer ligne par ligne pour ce batch\n",
    "            for borne in batch:\n",
    "                try:\n",
    "                    cursor_dwh.execute(insert_query, borne)\n",
    "                    insert_count += 1\n",
    "                except Exception as e_detail:\n",
    "                    print(f\"   ‚ùå Erreur insertion : {e_detail}\")\n",
    "                    print(f\"   Donn√©es probl√©matiques : INSEE={borne[8]}, nbre_pdc={borne[11]}\")\n",
    "            cnxn_dwh.commit()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Insertion termin√©e : {insert_count} bornes ins√©r√©es\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ Aucune nouvelle borne √† ins√©rer\")\n",
    "    insert_count = 0\n",
    "\n",
    "# ========================================\n",
    "# NETTOYAGE DES DOUBLONS\n",
    "# ========================================\n",
    "print(\"\\nüßπ NETTOYAGE DES DOUBLONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "print(\"‚è≥ D√©tection des doublons...\")\n",
    "cursor_dwh.execute(\"\"\"\n",
    "SELECT ID_Station, Type_Prise, Puissance_kW, COUNT(*) as Nb_Doublons\n",
    "FROM DIM_BORNE_RECHARGE\n",
    "GROUP BY ID_Station, Type_Prise, Puissance_kW\n",
    "HAVING COUNT(*) > 1\n",
    "\"\"\")\n",
    "\n",
    "doublons = cursor_dwh.fetchall()\n",
    "nb_groupes_doublons = len(doublons)\n",
    "\n",
    "if nb_groupes_doublons > 0:\n",
    "    print(f\"‚ö†Ô∏è  {nb_groupes_doublons} groupes de doublons trouv√©s\")\n",
    "    \n",
    "    total_doublons_supprimes = 0\n",
    "    \n",
    "    # Supprimer les doublons pour chaque groupe\n",
    "    for doublon in tqdm(doublons, desc=\"Suppression doublons\", unit=\"groupe\"):\n",
    "        id_station = doublon[0]\n",
    "        type_prise = doublon[1]\n",
    "        puissance = doublon[2]\n",
    "        nb_occurrences = doublon[3]\n",
    "        \n",
    "        # R√©cup√©rer tous les SK_Borne pour ce groupe\n",
    "        cursor_dwh.execute(\"\"\"\n",
    "        SELECT SK_Borne\n",
    "        FROM DIM_BORNE_RECHARGE\n",
    "        WHERE ID_Station = ? AND Type_Prise = ? AND Puissance_kW = ?\n",
    "        ORDER BY SK_Borne ASC\n",
    "        \"\"\", id_station, type_prise, puissance)\n",
    "        \n",
    "        sk_bornes = [row[0] for row in cursor_dwh.fetchall()]\n",
    "        \n",
    "        # Garder le premier (plus ancien), supprimer les autres\n",
    "        sk_a_garder = sk_bornes[0]\n",
    "        sk_a_supprimer = sk_bornes[1:]\n",
    "        \n",
    "        # Supprimer les doublons\n",
    "        for sk in sk_a_supprimer:\n",
    "            cursor_dwh.execute(\"\"\"\n",
    "            DELETE FROM DIM_BORNE_RECHARGE\n",
    "            WHERE SK_Borne = ?\n",
    "            \"\"\", sk)\n",
    "            total_doublons_supprimes += 1\n",
    "    \n",
    "    cnxn_dwh.commit()\n",
    "    \n",
    "    print(f\"\\n‚úÖ Nettoyage termin√© :\")\n",
    "    print(f\"   ‚Ä¢ {nb_groupes_doublons} groupes de doublons trait√©s\")\n",
    "    print(f\"   ‚Ä¢ {total_doublons_supprimes} enregistrements en doublon supprim√©s\")\n",
    "else:\n",
    "    print(\"‚úÖ Aucun doublon trouv√© dans DIM_BORNE_RECHARGE\")\n",
    "\n",
    "# ========================================\n",
    "# V√âRIFICATION FINALE\n",
    "# ========================================\n",
    "print(\"\\nüîç V√âRIFICATION FINALE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "cursor_dwh.execute(\"SELECT COUNT(*) FROM DIM_BORNE_RECHARGE\")\n",
    "total_final = cursor_dwh.fetchone()[0]\n",
    "print(f\"üìä Nombre total de bornes dans DIM_BORNE_RECHARGE : {total_final}\")\n",
    "\n",
    "# V√©rifier qu'il n'y a plus de doublons\n",
    "cursor_dwh.execute(\"\"\"\n",
    "SELECT COUNT(*) \n",
    "FROM (\n",
    "    SELECT ID_Station, Type_Prise, Puissance_kW, COUNT(*) as Nb\n",
    "    FROM DIM_BORNE_RECHARGE\n",
    "    GROUP BY ID_Station, Type_Prise, Puissance_kW\n",
    "    HAVING COUNT(*) > 1\n",
    ") AS Doublons\n",
    "\"\"\")\n",
    "nb_doublons_restants = cursor_dwh.fetchone()[0]\n",
    "\n",
    "if nb_doublons_restants == 0:\n",
    "    print(\"‚úÖ Aucun doublon d√©tect√© - Table propre !\")\n",
    "else:\n",
    "    print(f\"‚ö†Ô∏è  ATTENTION : {nb_doublons_restants} doublons restants d√©tect√©s\")\n",
    "\n",
    "# V√©rification de la r√©partition par d√©partement\n",
    "print(\"\\nüìç R√©partition des bornes par d√©partement (code INSEE) :\")\n",
    "cursor_dwh.execute(\"\"\"\n",
    "SELECT \n",
    "    LEFT(code_insee_commune, 2) as Dep_Code,\n",
    "    COUNT(*) as Nb_Bornes,\n",
    "    SUM(nbre_pdc) as Total_PDC\n",
    "FROM DIM_BORNE_RECHARGE\n",
    "WHERE code_insee_commune IS NOT NULL\n",
    "GROUP BY LEFT(code_insee_commune, 2)\n",
    "ORDER BY Nb_Bornes DESC\n",
    "\"\"\")\n",
    "\n",
    "for row in cursor_dwh.fetchall():\n",
    "    print(f\"   ‚Ä¢ D√©partement {row[0]} : {row[1]} bornes - {row[2]} points de charge\")\n",
    "\n",
    "# Statistiques sur les points de charge\n",
    "print(\"\\n‚ö° Statistiques sur les points de charge (PDC) :\")\n",
    "cursor_dwh.execute(\"\"\"\n",
    "SELECT \n",
    "    COUNT(*) as Nb_Stations,\n",
    "    SUM(nbre_pdc) as Total_PDC,\n",
    "    AVG(CAST(nbre_pdc AS FLOAT)) as Moyenne_PDC_Par_Station,\n",
    "    MIN(nbre_pdc) as Min_PDC,\n",
    "    MAX(nbre_pdc) as Max_PDC\n",
    "FROM DIM_BORNE_RECHARGE\n",
    "\"\"\")\n",
    "\n",
    "stats_pdc = cursor_dwh.fetchone()\n",
    "print(f\"   ‚Ä¢ Nombre total de stations : {stats_pdc[0]}\")\n",
    "print(f\"   ‚Ä¢ Total points de charge : {stats_pdc[1]}\")\n",
    "print(f\"   ‚Ä¢ Moyenne PDC/station : {stats_pdc[2]:.2f}\")\n",
    "print(f\"   ‚Ä¢ Min PDC : {stats_pdc[3]}\")\n",
    "print(f\"   ‚Ä¢ Max PDC : {stats_pdc[4]}\")\n",
    "\n",
    "# Afficher quelques exemples de bornes ins√©r√©es\n",
    "print(\"\\nüìç Exemples de bornes ins√©r√©es :\")\n",
    "cursor_dwh.execute(\"\"\"\n",
    "SELECT TOP 5 \n",
    "    ID_Station, Nom_Station, Type_Prise, Puissance_kW, \n",
    "    code_insee_commune, Xlongitude, Ylatitude, nbre_pdc\n",
    "FROM DIM_BORNE_RECHARGE\n",
    "ORDER BY SK_Borne DESC\n",
    "\"\"\")\n",
    "\n",
    "for row in cursor_dwh.fetchall():\n",
    "    print(f\"   ‚Ä¢ Station: {row[0]} | {row[1]}\")\n",
    "    print(f\"     Type: {row[2]} | Puissance: {row[3]} kW | PDC: {row[7]}\")\n",
    "    print(f\"     Commune INSEE: {row[4]} | Coords: ({row[5]}, {row[6]})\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(f\"‚úÖ CHARGEMENT TERMIN√â :\")\n",
    "print(f\"   ‚Ä¢ {insert_count} nouvelles bornes ins√©r√©es\")\n",
    "print(f\"   ‚Ä¢ {skip_count} bornes d√©j√† existantes (ignor√©es)\")\n",
    "if nb_groupes_doublons > 0:\n",
    "    print(f\"   ‚Ä¢ {total_doublons_supprimes} doublons supprim√©s\")\n",
    "print(f\"   ‚Ä¢ {total_final} bornes uniques au total\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f766916",
   "metadata": {},
   "source": [
    "üì¶ Cellule 09 : ETL - Chargement de FAIT_DISPONIBILITE_BORNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "dd5452a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üì• ETL - CHARGEMENT DE FAIT_DISPONIBILITE_BORNE\n",
      "======================================================================\n",
      "\n",
      "‚è≥ Extraction des donn√©es depuis DIM_BORNE_RECHARGE...\n",
      "‚úÖ 913 bornes extraites de DIM_BORNE_RECHARGE\n",
      "\n",
      "‚è≥ Chargement des r√©f√©rences DIM_GEOGRAPHIE...\n",
      "‚úÖ 3788 codes INSEE charg√©s\n",
      "\n",
      "‚è≥ Chargement des r√©f√©rences DIM_TEMPS...\n",
      "‚úÖ 4018 dates charg√©es\n",
      "\n",
      "‚è≥ R√©solution des cl√©s √©trang√®res (SK_Geographie, SK_Temps)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Traitement bornes: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 913/913 [00:00<00:00, 456641.97borne/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üìä RAPPORT DE R√âSOLUTION DES CL√âS :\n",
      "   ‚úÖ Lignes valides : 685\n",
      "   ‚ö†Ô∏è  Date introuvable dans DIM_TEMPS : 228\n",
      "\n",
      "‚è≥ Chargement des faits d√©j√† pr√©sents dans le DWH...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ 0 faits d√©j√† pr√©sents\n",
      "\n",
      "‚è≥ Filtrage des nouveaux faits √† ins√©rer...\n",
      "‚úÖ 685 nouveaux faits √† ins√©rer\n",
      "‚ö†Ô∏è  0 faits d√©j√† existants (ignor√©s)\n",
      "\n",
      "‚è≥ Insertion des nouveaux faits...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Insertion faits: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [01:54<00:00, 57.19s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ Insertion termin√©e : 685 faits ins√©r√©s\n",
      "\n",
      "üßπ NETTOYAGE DES DOUBLONS\n",
      "======================================================================\n",
      "‚è≥ D√©tection des doublons...\n",
      "‚úÖ Aucun doublon trouv√© dans FAIT_DISPONIBILITE_BORNE\n",
      "\n",
      "üîç V√âRIFICATION FINALE\n",
      "======================================================================\n",
      "üìä Nombre total de lignes dans FAIT_DISPONIBILITE_BORNE : 685\n",
      "\n",
      "üìà STATISTIQUES GLOBALES :\n",
      "   ‚Ä¢ Bornes uniques : 685\n",
      "   ‚Ä¢ Communes uniques : 292\n",
      "   ‚Ä¢ Dates uniques : 9\n",
      "   ‚Ä¢ Total points de charge : 2128\n",
      "   ‚Ä¢ Puissance moyenne : 23.51 kW\n",
      "   ‚Ä¢ P√©riode couverte : 2020-04-03 ‚Üí 2021-09-07\n",
      "\n",
      "üìç R√©partition par d√©partement :\n",
      "   ‚Ä¢ Nord (59) : 350 bornes - 1239 prises - 150 communes\n",
      "   ‚Ä¢ Pas-de-Calais (62) : 185 bornes - 578 prises - 70 communes\n",
      "   ‚Ä¢ Aisne (02) : 143 bornes - 284 prises - 67 communes\n",
      "   ‚Ä¢ Oise (60) : 4 bornes - 14 prises - 3 communes\n",
      "   ‚Ä¢ Somme (80) : 3 bornes - 13 prises - 2 communes\n",
      "\n",
      "üèÜ Top 10 des communes avec le plus de points de charge :\n",
      "   ‚Ä¢ Lezennes (Nord) : 5 bornes - 130 prises - 16.85 kW moy.\n",
      "   ‚Ä¢ Lille (Nord) : 13 bornes - 106 prises - 19.81 kW moy.\n",
      "   ‚Ä¢ Dechy (Nord) : 19 bornes - 87 prises - 26.11 kW moy.\n",
      "   ‚Ä¢ Soissons (Aisne) : 34 bornes - 68 prises - 22.00 kW moy.\n",
      "   ‚Ä¢ Li√©vin (Pas-de-Calais) : 12 bornes - 64 prises - 22.08 kW moy.\n",
      "   ‚Ä¢ Calais (Pas-de-Calais) : 12 bornes - 52 prises - 22.24 kW moy.\n",
      "   ‚Ä¢ Douai (Nord) : 22 bornes - 52 prises - 22.01 kW moy.\n",
      "   ‚Ä¢ Villeneuve-d'Ascq (Nord) : 13 bornes - 50 prises - 18.68 kW moy.\n",
      "   ‚Ä¢ Saint-L√©onard (Pas-de-Calais) : 11 bornes - 48 prises - 19.57 kW moy.\n",
      "   ‚Ä¢ Dunkerque (Nord) : 12 bornes - 48 prises - 22.24 kW moy.\n",
      "\n",
      "üîó V√âRIFICATION DE L'INT√âGRIT√â R√âF√âRENTIELLE :\n",
      "   ‚úÖ Toutes les cl√©s √©trang√®res sont valides\n",
      "   ‚úÖ Aucun doublon d√©tect√© (cl√© : SK_Borne + SK_Temps)\n",
      "\n",
      "üìã EXEMPLES DE FAITS INS√âR√âS :\n",
      "\n",
      "   üìÖ Date : 2020-04-03 (Vendredi)\n",
      "   üîå Station : FR*M59*P59609*001\n",
      "   üìç Localisation : VENDEVILLE - Rue de Seclin - Vendeville (Nord)\n",
      "   ‚ö° Capacit√© : 2 prises - 18.00 kW\n",
      "\n",
      "   üìÖ Date : 2020-06-26 (Vendredi)\n",
      "   üîå Station : FR*S60*PJYVUUB\n",
      "   üìç Localisation : Chambly, Rue Raymond Joly - Chambly (Oise)\n",
      "   ‚ö° Capacit√© : 2 prises - 22.00 kW\n",
      "\n",
      "   üìÖ Date : 2021-03-03 (Mercredi)\n",
      "   üîå Station : FR*SSD*PLEMPEREURMAZDA59187*1\n",
      "   üìç Localisation : Mazda Douai / Dechy - Dechy (Nord)\n",
      "   ‚ö° Capacit√© : 4 prises - 22.08 kW\n",
      "\n",
      "   üìÖ Date : 2021-03-03 (Mercredi)\n",
      "   üîå Station : FR*SSD*PASLAREAENGLOS59320*1\n",
      "   üìç Localisation : ASL AREA Englos - Englos (Nord)\n",
      "   ‚ö° Capacit√© : 2 prises - 22.08 kW\n",
      "\n",
      "   üìÖ Date : 2020-04-03 (Vendredi)\n",
      "   üîå Station : FR*H07*P59574*003\n",
      "   üìç Localisation : SOMAIN - Boulevard Louise Michel - Somain (Nord)\n",
      "   ‚ö° Capacit√© : 3 prises - 43.00 kW\n",
      "\n",
      "======================================================================\n",
      "‚úÖ CHARGEMENT TERMIN√â - FAIT_DISPONIBILITE_BORNE\n",
      "======================================================================\n",
      "   üìä Total de lignes dans la table : 685\n",
      "   ‚ûï Nouvelles lignes ins√©r√©es : 685\n",
      "   ‚è≠Ô∏è  Lignes d√©j√† existantes (ignor√©es) : 0\n",
      "\n",
      "   üìå R√©solution des cl√©s :\n",
      "      ‚Ä¢ Lignes valides : 685\n",
      "      ‚Ä¢ Dates introuvables : 228\n",
      "\n",
      "   üéØ Couverture :\n",
      "      ‚Ä¢ 685 bornes uniques\n",
      "      ‚Ä¢ 292 communes √©quip√©es\n",
      "      ‚Ä¢ 2128 points de charge au total\n",
      "      ‚Ä¢ P√©riode : 2020-04-03 ‚Üí 2021-09-07\n",
      "======================================================================\n",
      "\n",
      "‚úÖ Cellule 9 termin√©e avec succ√®s !\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "print(\"\\nüì• ETL - CHARGEMENT DE FAIT_DISPONIBILITE_BORNE\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ========================================\n",
    "# √âTAPE 1 : EXTRACTION DES DONN√âES DEPUIS DIM_BORNE_RECHARGE\n",
    "# ========================================\n",
    "print(\"\\n‚è≥ Extraction des donn√©es depuis DIM_BORNE_RECHARGE...\")\n",
    "\n",
    "cursor_dwh.execute(\"\"\"\n",
    "SELECT \n",
    "    SK_Borne,\n",
    "    code_insee_commune,\n",
    "    nbre_pdc,\n",
    "    Puissance_kW,\n",
    "    Date_Mise_Service\n",
    "FROM DIM_BORNE_RECHARGE\n",
    "WHERE Date_Mise_Service IS NOT NULL\n",
    "    AND code_insee_commune IS NOT NULL\n",
    "    AND code_insee_commune != '00000'\n",
    "ORDER BY SK_Borne\n",
    "\"\"\")\n",
    "\n",
    "bornes_source = cursor_dwh.fetchall()\n",
    "print(f\"‚úÖ {len(bornes_source)} bornes extraites de DIM_BORNE_RECHARGE\")\n",
    "\n",
    "if len(bornes_source) == 0:\n",
    "    print(\"‚ö†Ô∏è  Aucune borne √† traiter. V√©rifiez DIM_BORNE_RECHARGE.\")\n",
    "    print(\"=\" * 70)\n",
    "else:\n",
    "    # ========================================\n",
    "    # √âTAPE 2 : CHARGEMENT DES TABLES DE R√âF√âRENCE EN M√âMOIRE\n",
    "    # ========================================\n",
    "    print(\"\\n‚è≥ Chargement des r√©f√©rences DIM_GEOGRAPHIE...\")\n",
    "    cursor_dwh.execute(\"SELECT Code_INSEE, SK_Geographie FROM DIM_GEOGRAPHIE\")\n",
    "    mapping_geo = {row[0]: row[1] for row in cursor_dwh.fetchall()}\n",
    "    print(f\"‚úÖ {len(mapping_geo)} codes INSEE charg√©s\")\n",
    "\n",
    "    print(\"\\n‚è≥ Chargement des r√©f√©rences DIM_TEMPS...\")\n",
    "    cursor_dwh.execute(\"SELECT CAST(Date AS DATE), SK_Temps FROM DIM_TEMPS\")\n",
    "    mapping_temps = {row[0]: row[1] for row in cursor_dwh.fetchall()}\n",
    "    print(f\"‚úÖ {len(mapping_temps)} dates charg√©es\")\n",
    "\n",
    "    # ========================================\n",
    "    # √âTAPE 3 : R√âSOLUTION DES CL√âS √âTRANG√àRES\n",
    "    # ========================================\n",
    "    print(\"\\n‚è≥ R√©solution des cl√©s √©trang√®res (SK_Geographie, SK_Temps)...\")\n",
    "    \n",
    "    faits_a_inserer = []\n",
    "    stats_erreurs = {\n",
    "        'geo_introuvable': 0,\n",
    "        'temps_introuvable': 0,\n",
    "        'date_null': 0,\n",
    "        'valides': 0\n",
    "    }\n",
    "    \n",
    "    for borne in tqdm(bornes_source, desc=\"Traitement bornes\", unit=\"borne\"):\n",
    "        sk_borne = borne[0]\n",
    "        code_insee = borne[1]\n",
    "        nbre_pdc = borne[2] if borne[2] is not None else 0\n",
    "        puissance_kw = borne[3] if borne[3] is not None else 0.0\n",
    "        date_mise_service = borne[4]\n",
    "        \n",
    "        # V√©rification de la date\n",
    "        if date_mise_service is None:\n",
    "            stats_erreurs['date_null'] += 1\n",
    "            continue\n",
    "        \n",
    "        # R√©soudre SK_Geographie via code INSEE\n",
    "        sk_geographie = mapping_geo.get(code_insee)\n",
    "        if sk_geographie is None:\n",
    "            stats_erreurs['geo_introuvable'] += 1\n",
    "            continue\n",
    "        \n",
    "        # R√©soudre SK_Temps via Date_Mise_Service\n",
    "        # Convertir en date si n√©cessaire\n",
    "        if isinstance(date_mise_service, str):\n",
    "            from datetime import datetime\n",
    "            date_mise_service = datetime.strptime(date_mise_service, '%Y-%m-%d').date()\n",
    "        \n",
    "        sk_temps = mapping_temps.get(date_mise_service)\n",
    "        if sk_temps is None:\n",
    "            stats_erreurs['temps_introuvable'] += 1\n",
    "            continue\n",
    "        \n",
    "        # ‚úÖ Tout est OK, on pr√©pare l'insertion\n",
    "        stats_erreurs['valides'] += 1\n",
    "        faits_a_inserer.append((\n",
    "            sk_temps,\n",
    "            sk_borne,\n",
    "            sk_geographie,\n",
    "            int(nbre_pdc),  # Nombre_prise_disponible\n",
    "            float(puissance_kw),  # Puissance_Totale_kW\n",
    "            date_mise_service  # Date_MAJ\n",
    "        ))\n",
    "    \n",
    "    # ========================================\n",
    "    # RAPPORT DE R√âSOLUTION\n",
    "    # ========================================\n",
    "    print(f\"\\nüìä RAPPORT DE R√âSOLUTION DES CL√âS :\")\n",
    "    print(f\"   ‚úÖ Lignes valides : {stats_erreurs['valides']}\")\n",
    "    if stats_erreurs['geo_introuvable'] > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  G√©ographie introuvable : {stats_erreurs['geo_introuvable']}\")\n",
    "    if stats_erreurs['temps_introuvable'] > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  Date introuvable dans DIM_TEMPS : {stats_erreurs['temps_introuvable']}\")\n",
    "    if stats_erreurs['date_null'] > 0:\n",
    "        print(f\"   ‚ö†Ô∏è  Date NULL ignor√©e : {stats_erreurs['date_null']}\")\n",
    "    \n",
    "    # ========================================\n",
    "    # √âTAPE 4 : CHARGER LES FAITS EXISTANTS\n",
    "    # ========================================\n",
    "    print(\"\\n‚è≥ Chargement des faits d√©j√† pr√©sents dans le DWH...\")\n",
    "    cursor_dwh.execute(\"\"\"\n",
    "    SELECT SK_Borne, SK_Temps\n",
    "    FROM FAIT_DISPONIBILITE_BORNE\n",
    "    \"\"\")\n",
    "    \n",
    "    faits_existants = set()\n",
    "    for row in cursor_dwh.fetchall():\n",
    "        cle = (row[0], row[1])  # (SK_Borne, SK_Temps)\n",
    "        faits_existants.add(cle)\n",
    "    \n",
    "    print(f\"‚úÖ {len(faits_existants)} faits d√©j√† pr√©sents\")\n",
    "    \n",
    "    # ========================================\n",
    "    # √âTAPE 5 : FILTRER LES NOUVEAUX FAITS\n",
    "    # ========================================\n",
    "    print(\"\\n‚è≥ Filtrage des nouveaux faits √† ins√©rer...\")\n",
    "    nouveaux_faits = []\n",
    "    \n",
    "    for fait in faits_a_inserer:\n",
    "        sk_temps = fait[0]\n",
    "        sk_borne = fait[1]\n",
    "        cle = (sk_borne, sk_temps)\n",
    "        \n",
    "        if cle not in faits_existants:\n",
    "            nouveaux_faits.append(fait)\n",
    "    \n",
    "    skip_count = len(faits_a_inserer) - len(nouveaux_faits)\n",
    "    print(f\"‚úÖ {len(nouveaux_faits)} nouveaux faits √† ins√©rer\")\n",
    "    print(f\"‚ö†Ô∏è  {skip_count} faits d√©j√† existants (ignor√©s)\")\n",
    "    \n",
    "    # ========================================\n",
    "    # √âTAPE 6 : INSERTION PAR BATCH\n",
    "    # ========================================\n",
    "    if len(nouveaux_faits) > 0:\n",
    "        print(\"\\n‚è≥ Insertion des nouveaux faits...\")\n",
    "        \n",
    "        insert_query = \"\"\"\n",
    "        INSERT INTO FAIT_DISPONIBILITE_BORNE (\n",
    "            SK_Temps,\n",
    "            SK_Borne,\n",
    "            SK_Geographie,\n",
    "            Nombre_prise_disponible,\n",
    "            Puissance_Totale_kW,\n",
    "            Date_MAJ\n",
    "        )\n",
    "        VALUES (?, ?, ?, ?, ?, ?)\n",
    "        \"\"\"\n",
    "        \n",
    "        batch_size = 500\n",
    "        insert_count = 0\n",
    "        \n",
    "        for i in tqdm(range(0, len(nouveaux_faits), batch_size), desc=\"Insertion faits\", unit=\"batch\"):\n",
    "            batch = nouveaux_faits[i:i+batch_size]\n",
    "            \n",
    "            try:\n",
    "                cursor_dwh.executemany(insert_query, batch)\n",
    "                cnxn_dwh.commit()\n",
    "                insert_count += len(batch)\n",
    "            except Exception as e:\n",
    "                print(f\"\\n‚ö†Ô∏è  Erreur lors de l'insertion du batch {i//batch_size + 1} : {e}\")\n",
    "                # En cas d'erreur, ins√©rer ligne par ligne\n",
    "                for fait in batch:\n",
    "                    try:\n",
    "                        cursor_dwh.execute(insert_query, fait)\n",
    "                        insert_count += 1\n",
    "                    except Exception as e_detail:\n",
    "                        print(f\"   ‚ùå Erreur insertion : {e_detail}\")\n",
    "                        print(f\"   Donn√©es : SK_Temps={fait[0]}, SK_Borne={fait[1]}, SK_Geo={fait[2]}\")\n",
    "                cnxn_dwh.commit()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Insertion termin√©e : {insert_count} faits ins√©r√©s\")\n",
    "    else:\n",
    "        print(\"\\n‚úÖ Aucun nouveau fait √† ins√©rer\")\n",
    "        insert_count = 0\n",
    "    \n",
    "    # ========================================\n",
    "    # √âTAPE 7 : NETTOYAGE DES DOUBLONS\n",
    "    # ========================================\n",
    "    print(\"\\nüßπ NETTOYAGE DES DOUBLONS\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    print(\"‚è≥ D√©tection des doublons...\")\n",
    "    cursor_dwh.execute(\"\"\"\n",
    "    SELECT SK_Borne, SK_Temps, COUNT(*) as Nb_Doublons\n",
    "    FROM FAIT_DISPONIBILITE_BORNE\n",
    "    GROUP BY SK_Borne, SK_Temps\n",
    "    HAVING COUNT(*) > 1\n",
    "    \"\"\")\n",
    "    \n",
    "    doublons = cursor_dwh.fetchall()\n",
    "    nb_groupes_doublons = len(doublons)\n",
    "    \n",
    "    if nb_groupes_doublons > 0:\n",
    "        print(f\"‚ö†Ô∏è  {nb_groupes_doublons} groupes de doublons trouv√©s\")\n",
    "        \n",
    "        total_doublons_supprimes = 0\n",
    "        \n",
    "        # Supprimer les doublons (garder 1 seule ligne par combinaison SK_Borne + SK_Temps)\n",
    "        for doublon in tqdm(doublons, desc=\"Suppression doublons\", unit=\"groupe\"):\n",
    "            sk_borne = doublon[0]\n",
    "            sk_temps = doublon[1]\n",
    "            \n",
    "            # Supprimer tous sauf le premier (on ne garde qu'une ligne)\n",
    "            cursor_dwh.execute(\"\"\"\n",
    "            DELETE FROM FAIT_DISPONIBILITE_BORNE\n",
    "            WHERE SK_Borne = ? AND SK_Temps = ?\n",
    "            AND NOT EXISTS (\n",
    "                SELECT TOP 1 1\n",
    "                FROM FAIT_DISPONIBILITE_BORNE f2\n",
    "                WHERE f2.SK_Borne = FAIT_DISPONIBILITE_BORNE.SK_Borne\n",
    "                    AND f2.SK_Temps = FAIT_DISPONIBILITE_BORNE.SK_Temps\n",
    "                ORDER BY f2.SK_Geographie ASC\n",
    "            )\n",
    "            \"\"\", sk_borne, sk_temps)\n",
    "            \n",
    "            total_doublons_supprimes += cursor_dwh.rowcount\n",
    "        \n",
    "        cnxn_dwh.commit()\n",
    "        \n",
    "        print(f\"\\n‚úÖ Nettoyage termin√© :\")\n",
    "        print(f\"   ‚Ä¢ {nb_groupes_doublons} groupes de doublons trait√©s\")\n",
    "        print(f\"   ‚Ä¢ {total_doublons_supprimes} enregistrements en doublon supprim√©s\")\n",
    "    else:\n",
    "        print(\"‚úÖ Aucun doublon trouv√© dans FAIT_DISPONIBILITE_BORNE\")\n",
    "    \n",
    "    # ========================================\n",
    "    # √âTAPE 8 : V√âRIFICATIONS FINALES\n",
    "    # ========================================\n",
    "    print(\"\\nüîç V√âRIFICATION FINALE\")\n",
    "    print(\"=\" * 70)\n",
    "    \n",
    "    cursor_dwh.execute(\"SELECT COUNT(*) FROM FAIT_DISPONIBILITE_BORNE\")\n",
    "    total_final = cursor_dwh.fetchone()[0]\n",
    "    print(f\"üìä Nombre total de lignes dans FAIT_DISPONIBILITE_BORNE : {total_final}\")\n",
    "    \n",
    "    # Statistiques globales\n",
    "    print(\"\\nüìà STATISTIQUES GLOBALES :\")\n",
    "    cursor_dwh.execute(\"\"\"\n",
    "    SELECT \n",
    "        COUNT(DISTINCT SK_Borne) as Nb_Bornes_Uniques,\n",
    "        COUNT(DISTINCT SK_Geographie) as Nb_Communes_Uniques,\n",
    "        COUNT(DISTINCT SK_Temps) as Nb_Dates_Uniques,\n",
    "        SUM(Nombre_prise_disponible) as Total_Prises,\n",
    "        AVG(CAST(Puissance_Totale_kW AS FLOAT)) as Puissance_Moyenne,\n",
    "        MIN(Date_MAJ) as Date_Min,\n",
    "        MAX(Date_MAJ) as Date_Max\n",
    "    FROM FAIT_DISPONIBILITE_BORNE\n",
    "    \"\"\")\n",
    "    \n",
    "    stats = cursor_dwh.fetchone()\n",
    "    print(f\"   ‚Ä¢ Bornes uniques : {stats[0]}\")\n",
    "    print(f\"   ‚Ä¢ Communes uniques : {stats[1]}\")\n",
    "    print(f\"   ‚Ä¢ Dates uniques : {stats[2]}\")\n",
    "    print(f\"   ‚Ä¢ Total points de charge : {stats[3]}\")\n",
    "    print(f\"   ‚Ä¢ Puissance moyenne : {stats[4]:.2f} kW\")\n",
    "    print(f\"   ‚Ä¢ P√©riode couverte : {stats[5]} ‚Üí {stats[6]}\")\n",
    "    \n",
    "    # R√©partition par d√©partement\n",
    "    print(\"\\nüìç R√©partition par d√©partement :\")\n",
    "    cursor_dwh.execute(\"\"\"\n",
    "    SELECT \n",
    "        g.Dep_Code,\n",
    "        g.Dep_Nom,\n",
    "        COUNT(DISTINCT f.SK_Borne) as Nb_Bornes,\n",
    "        SUM(f.Nombre_prise_disponible) as Total_Prises,\n",
    "        COUNT(DISTINCT f.SK_Geographie) as Nb_Communes\n",
    "    FROM FAIT_DISPONIBILITE_BORNE f\n",
    "    JOIN DIM_GEOGRAPHIE g ON f.SK_Geographie = g.SK_Geographie\n",
    "    GROUP BY g.Dep_Code, g.Dep_Nom\n",
    "    ORDER BY Nb_Bornes DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    \n",
    "    for row in cursor_dwh.fetchall():\n",
    "        print(f\"   ‚Ä¢ {row[1]} ({row[0]}) : {row[2]} bornes - {row[3]} prises - {row[4]} communes\")\n",
    "    \n",
    "    # Top 10 des communes avec le plus de prises\n",
    "    print(\"\\nüèÜ Top 10 des communes avec le plus de points de charge :\")\n",
    "    cursor_dwh.execute(\"\"\"\n",
    "    SELECT TOP 10\n",
    "        g.Nom_Commune,\n",
    "        g.Dep_Nom,\n",
    "        COUNT(DISTINCT f.SK_Borne) as Nb_Bornes,\n",
    "        SUM(f.Nombre_prise_disponible) as Total_Prises,\n",
    "        AVG(CAST(f.Puissance_Totale_kW AS FLOAT)) as Puissance_Moyenne\n",
    "    FROM FAIT_DISPONIBILITE_BORNE f\n",
    "    JOIN DIM_GEOGRAPHIE g ON f.SK_Geographie = g.SK_Geographie\n",
    "    GROUP BY g.Nom_Commune, g.Dep_Nom\n",
    "    ORDER BY Total_Prises DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    for row in cursor_dwh.fetchall():\n",
    "        print(f\"   ‚Ä¢ {row[0]} ({row[1]}) : {row[2]} bornes - {row[3]} prises - {row[4]:.2f} kW moy.\")\n",
    "    \n",
    "    # V√©rification de l'int√©grit√© r√©f√©rentielle\n",
    "    print(\"\\nüîó V√âRIFICATION DE L'INT√âGRIT√â R√âF√âRENTIELLE :\")\n",
    "    \n",
    "    # V√©rifier les FK vers DIM_BORNE_RECHARGE\n",
    "    cursor_dwh.execute(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM FAIT_DISPONIBILITE_BORNE f\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM DIM_BORNE_RECHARGE b \n",
    "        WHERE b.SK_Borne = f.SK_Borne\n",
    "    )\n",
    "    \"\"\")\n",
    "    orphelins_borne = cursor_dwh.fetchone()[0]\n",
    "    \n",
    "    # V√©rifier les FK vers DIM_GEOGRAPHIE\n",
    "    cursor_dwh.execute(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM FAIT_DISPONIBILITE_BORNE f\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM DIM_GEOGRAPHIE g \n",
    "        WHERE g.SK_Geographie = f.SK_Geographie\n",
    "    )\n",
    "    \"\"\")\n",
    "    orphelins_geo = cursor_dwh.fetchone()[0]\n",
    "    \n",
    "    # V√©rifier les FK vers DIM_TEMPS\n",
    "    cursor_dwh.execute(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM FAIT_DISPONIBILITE_BORNE f\n",
    "    WHERE NOT EXISTS (\n",
    "        SELECT 1 FROM DIM_TEMPS t \n",
    "        WHERE t.SK_Temps = f.SK_Temps\n",
    "    )\n",
    "    \"\"\")\n",
    "    orphelins_temps = cursor_dwh.fetchone()[0]\n",
    "    \n",
    "    if orphelins_borne == 0 and orphelins_geo == 0 and orphelins_temps == 0:\n",
    "        print(\"   ‚úÖ Toutes les cl√©s √©trang√®res sont valides\")\n",
    "    else:\n",
    "        if orphelins_borne > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  {orphelins_borne} faits avec SK_Borne orphelin\")\n",
    "        if orphelins_geo > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  {orphelins_geo} faits avec SK_Geographie orphelin\")\n",
    "        if orphelins_temps > 0:\n",
    "            print(f\"   ‚ö†Ô∏è  {orphelins_temps} faits avec SK_Temps orphelin\")\n",
    "    \n",
    "    # V√©rifier les doublons restants\n",
    "    cursor_dwh.execute(\"\"\"\n",
    "    SELECT COUNT(*) \n",
    "    FROM (\n",
    "        SELECT SK_Borne, SK_Temps, COUNT(*) as Nb\n",
    "        FROM FAIT_DISPONIBILITE_BORNE\n",
    "        GROUP BY SK_Borne, SK_Temps\n",
    "        HAVING COUNT(*) > 1\n",
    "    ) AS Doublons\n",
    "    \"\"\")\n",
    "    nb_doublons_restants = cursor_dwh.fetchone()[0]\n",
    "    \n",
    "    if nb_doublons_restants == 0:\n",
    "        print(\"   ‚úÖ Aucun doublon d√©tect√© (cl√© : SK_Borne + SK_Temps)\")\n",
    "    else:\n",
    "        print(f\"   ‚ö†Ô∏è  ATTENTION : {nb_doublons_restants} doublons restants d√©tect√©s\")\n",
    "    \n",
    "    # Afficher quelques exemples de faits ins√©r√©s\n",
    "    print(\"\\nüìã EXEMPLES DE FAITS INS√âR√âS :\")\n",
    "    cursor_dwh.execute(\"\"\"\n",
    "    SELECT TOP 5\n",
    "        t.Date,\n",
    "        t.Jour_Semaine,\n",
    "        b.ID_Station,\n",
    "        b.Nom_Station,\n",
    "        g.Nom_Commune,\n",
    "        g.Dep_Nom,\n",
    "        f.Nombre_prise_disponible,\n",
    "        f.Puissance_Totale_kW\n",
    "    FROM FAIT_DISPONIBILITE_BORNE f\n",
    "    JOIN DIM_TEMPS t ON f.SK_Temps = t.SK_Temps\n",
    "    JOIN DIM_BORNE_RECHARGE b ON f.SK_Borne = b.SK_Borne\n",
    "    JOIN DIM_GEOGRAPHIE g ON f.SK_Geographie = g.SK_Geographie\n",
    "    ORDER BY f.SK_Borne DESC\n",
    "    \"\"\")\n",
    "    \n",
    "    for row in cursor_dwh.fetchall():\n",
    "        print(f\"\\n   üìÖ Date : {row[0]} ({row[1]})\")\n",
    "        print(f\"   üîå Station : {row[2]}\")\n",
    "        print(f\"   üìç Localisation : {row[3]} - {row[4]} ({row[5]})\")\n",
    "        print(f\"   ‚ö° Capacit√© : {row[6]} prises - {row[7]} kW\")\n",
    "    \n",
    "    # ========================================\n",
    "    # R√âSUM√â FINAL\n",
    "    # ========================================\n",
    "    print(\"\\n\" + \"=\" * 70)\n",
    "    print(\"‚úÖ CHARGEMENT TERMIN√â - FAIT_DISPONIBILITE_BORNE\")\n",
    "    print(\"=\" * 70)\n",
    "    print(f\"   üìä Total de lignes dans la table : {total_final}\")\n",
    "    print(f\"   ‚ûï Nouvelles lignes ins√©r√©es : {insert_count}\")\n",
    "    print(f\"   ‚è≠Ô∏è  Lignes d√©j√† existantes (ignor√©es) : {skip_count}\")\n",
    "    if nb_groupes_doublons > 0:\n",
    "        print(f\"   üßπ Doublons supprim√©s : {total_doublons_supprimes}\")\n",
    "    print(f\"\\n   üìå R√©solution des cl√©s :\")\n",
    "    print(f\"      ‚Ä¢ Lignes valides : {stats_erreurs['valides']}\")\n",
    "    if stats_erreurs['geo_introuvable'] > 0:\n",
    "        print(f\"      ‚Ä¢ G√©ographies introuvables : {stats_erreurs['geo_introuvable']}\")\n",
    "    if stats_erreurs['temps_introuvable'] > 0:\n",
    "        print(f\"      ‚Ä¢ Dates introuvables : {stats_erreurs['temps_introuvable']}\")\n",
    "    if stats_erreurs['date_null'] > 0:\n",
    "        print(f\"      ‚Ä¢ Dates NULL ignor√©es : {stats_erreurs['date_null']}\")\n",
    "    print(\"\\n   üéØ Couverture :\")\n",
    "    print(f\"      ‚Ä¢ {stats[0]} bornes uniques\")\n",
    "    print(f\"      ‚Ä¢ {stats[1]} communes √©quip√©es\")\n",
    "    print(f\"      ‚Ä¢ {stats[3]} points de charge au total\")\n",
    "    print(f\"      ‚Ä¢ P√©riode : {stats[5]} ‚Üí {stats[6]}\")\n",
    "    print(\"=\" * 70)\n",
    "\n",
    "print(\"\\n‚úÖ Cellule 9 termin√©e avec succ√®s !\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "699220cf",
   "metadata": {},
   "source": [
    "üìä Cellule 10 : Contr√¥le Qualit√© des Donn√©es du DWH + Fermeture des Connexions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1a160f48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "üîí FERMETURE DES CONNEXIONS\n",
      "======================================================================\n",
      "‚úÖ Curseur DWH ferm√©\n",
      "‚úÖ Connexion DWH ferm√©e\n",
      "\n",
      "======================================================================\n",
      "‚úÖ Toutes les connexions ont √©t√© ferm√©es avec succ√®s\n",
      "======================================================================\n",
      "\n",
      "üéâ FIN DU NOTEBOOK - ETL TERMIN√â\n",
      "\n",
      "üìä R√âSUM√â DES TABLES CHARG√âES :\n",
      "   ‚Ä¢ DIM_GEOGRAPHIE\n",
      "   ‚Ä¢ DIM_BORNE_RECHARGE\n",
      "   ‚Ä¢ DIM_TEMPS\n",
      "   ‚Ä¢ FAIT_DISPONIBILITE_BORNE\n",
      "\n",
      "üíæ Votre Data Warehouse est maintenant pr√™t pour l'analyse !\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nüîí FERMETURE DES CONNEXIONS\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# ========================================\n",
    "# FERMETURE DU CURSEUR DWH\n",
    "# ========================================\n",
    "try:\n",
    "    if 'cursor_dwh' in locals() and cursor_dwh:\n",
    "        cursor_dwh.close()\n",
    "        print(\"‚úÖ Curseur DWH ferm√©\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur lors de la fermeture du curseur : {e}\")\n",
    "\n",
    "# ========================================\n",
    "# FERMETURE DE LA CONNEXION DWH\n",
    "# ========================================\n",
    "try:\n",
    "    if 'cnxn_dwh' in locals() and cnxn_dwh:\n",
    "        cnxn_dwh.close()\n",
    "        print(\"‚úÖ Connexion DWH ferm√©e\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ö†Ô∏è  Erreur lors de la fermeture de la connexion : {e}\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 70)\n",
    "print(\"‚úÖ Toutes les connexions ont √©t√© ferm√©es avec succ√®s\")\n",
    "print(\"=\" * 70)\n",
    "print(\"\\nüéâ FIN DU NOTEBOOK - ETL TERMIN√â\")\n",
    "print(\"\\nüìä R√âSUM√â DES TABLES CHARG√âES :\")\n",
    "print(\"   ‚Ä¢ DIM_GEOGRAPHIE\")\n",
    "print(\"   ‚Ä¢ DIM_BORNE_RECHARGE\")\n",
    "print(\"   ‚Ä¢ DIM_TEMPS\")\n",
    "print(\"   ‚Ä¢ FAIT_DISPONIBILITE_BORNE\")\n",
    "print(\"\\nüíæ Votre Data Warehouse est maintenant pr√™t pour l'analyse !\")\n",
    "print(\"=\" * 70)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
