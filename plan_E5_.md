# ðŸŽ¯ PLAN COMPLET DU PROJET E5 - DATA WAREHOUSE
## AlignÃ© sur les compÃ©tences de certification C13, C14, C15

---

## ðŸ“‹ **PHASE 1 : ANALYSE MÃ‰TIER ET INVENTAIRE DES DONNÃ‰ES**
**ðŸŽ“ CompÃ©tence visÃ©e : C13 (prÃ©paration) + Exigence certification "produire une liste des donnÃ©es nÃ©cessaires"**

### **Ã‰tape 1.1 : DÃ©finition des besoins mÃ©tier**
- Identifier les cas d'usage : Site web automobile + Tableaux de bord dÃ©cisionnels
- DÃ©finir les questions mÃ©tier auxquelles le DWH doit rÃ©pondre
- Lister les KPI attendus (prix pneus, densitÃ© bornes, garages auto par zone)

### **Ã‰tape 1.2 : Inventaire exhaustif des sources de donnÃ©es**
**ðŸ“„ Livrable : "Liste des donnÃ©es nÃ©cessaires aux analyses envisagÃ©es"**

| Source | Localisation | Usage DWH |
|--------|--------------|-----------|
| Produit, Caracteristiques, Dimensions | Azure SQL | Dimensions + Faits Prix |
| DimensionsParModel | Azure SQL | Dimension VÃ©hicule |
| USER_API | Azure SQL | AgrÃ©gat comptage |
| SIRENE (42M lignes) | Data Lake Parquet | Dimension Entreprise (filtrÃ©e auto) |
| NAF | Data Lake XLS | Dimension ActivitÃ© |
| Bornes IRVE | Data Lake CSV | Fait Bornes + Dimension Borne |
| Communes France | Data Lake CSV | Dimension GÃ©ographie |
| ParuVendu brut | Data Lake CSV | Enrichissement VÃ©hicule |

### **Ã‰tape 1.3 : Identification des axes d'analyse (Dimensions)**
- **DIM_TEMPS** : Jour, Mois, Trimestre, AnnÃ©e, Saison
- **DIM_PRODUIT_PNEU** : Descriptif, Marque, Note
- **DIM_CARACTERISTIQUES_PNEU** : SaisonnalitÃ©, Type vÃ©hicule, Consommation, Bruit
- **DIM_DIMENSIONS_PNEU** : Largeur, Hauteur, DiamÃ¨tre, Charge, Vitesse
- **DIM_VEHICULE** : Marque, ModÃ¨le, AnnÃ©e, Finition, Energie
- **DIM_GEOGRAPHIE** : HiÃ©rarchie RÃ©gion â†’ DÃ©partement â†’ Commune (avec INSEE, population, coordonnÃ©es)
- **DIM_ENTREPRISE** : SIRET, SIREN, DÃ©nomination, NAF, Adresse (filtrÃ© secteur automobile)
- **DIM_ACTIVITE_NAF** : Code NAF, LibellÃ©s, HiÃ©rarchie Section/Division
- **DIM_BORNE_RECHARGE** : Type, Puissance, OpÃ©rateur, Statut

### **Ã‰tape 1.4 : Identification des indicateurs (Faits)**
- **FAIT_PRIX_PNEU** : Prix, Date scraping (historisation quotidienne)
- **FAIT_DISPONIBILITE_BORNE** : Nombre bornes, Puissance totale (snapshot mensuel)
- **FAIT_ENTREPRISE_AUTOMOBILE** : Nombre Ã©tablissements actifs par zone (snapshot mensuel)

### **Ã‰tape 1.5 : DÃ©finition de l'architecture des datamarts**
- **DATAMART_PNEUMATIQUES** : Analyses prix/caractÃ©ristiques pneus
- **DATAMART_MOBILITE_ELECTRIQUE** : Analyses bornes de recharge
- **DATAMART_ENTREPRISES_AUTOMOBILE** : Analyses garages/entreprises auto
- **Tables transverses** : DIM_TEMPS, DIM_GEOGRAPHIE (partagÃ©es)

---

## ðŸ“ **PHASE 2 : MODÃ‰LISATION DIMENSIONNELLE**
**ðŸŽ“ CompÃ©tence visÃ©e : C13 - ModÃ©liser la structure des donnÃ©es**
**ðŸ“„ Livrable : "ModÃ©lisations logiques et physiques de l'entrepÃ´t de donnÃ©es et des datamarts"**

### **Ã‰tape 2.1 : CrÃ©ation du ModÃ¨le Logique de DonnÃ©es (MLD)**
- SchÃ©ma en Ã©toile (star schema) pour chaque datamart
- Identification des clÃ©s de substitution (surrogate keys) pour toutes les dimensions
- Diagramme des relations Faits â†” Dimensions
- Documentation des cardinalitÃ©s et dÃ©pendances fonctionnelles

### **Ã‰tape 2.2 : StratÃ©gie de gestion de l'historisation (SCD)**
- **SCD Type 0** : DIM_TEMPS, DIM_ACTIVITE_NAF (donnÃ©es de rÃ©fÃ©rence figÃ©es)
- **SCD Type 1** : DIM_BORNE_RECHARGE (Ã©crasement du statut)
- **SCD Type 2** : DIM_PRODUIT_PNEU (historisation des prix avec Date_Debut/Date_Fin/Flag_Actuel), DIM_ENTREPRISE (historisation Ã©tat administratif)

### **Ã‰tape 2.3 : CrÃ©ation du ModÃ¨le Physique de DonnÃ©es (MPD)**
- DÃ©finition des types de donnÃ©es SQL Server prÃ©cis (INT, VARCHAR, DECIMAL, DATE)
- Scripts DDL de crÃ©ation de toutes les tables (Dimensions + Faits)
- Contraintes d'intÃ©gritÃ© (PRIMARY KEY, FOREIGN KEY, NOT NULL, CHECK)
- StratÃ©gie d'indexation :
  - Index clustered sur clÃ©s de substitution des dimensions
  - Index columnstore sur tables de faits (performances requÃªtes analytiques)
  - Index non-clustered sur colonnes de filtrage frÃ©quentes

### **Ã‰tape 2.4 : Conception des agrÃ©gats prÃ©-calculÃ©s (optionnel)**
- Tables d'agrÃ©gats pour accÃ©lÃ©rer les requÃªtes BI frÃ©quentes
- Exemple : AGG_PRIX_MOYEN_PAR_DIMENSION_MOIS

### **Ã‰tape 2.5 : Validation du modÃ¨le**
- Revue du modÃ¨le avec les exigences mÃ©tier (Phase 1)
- VÃ©rification de la couverture de tous les KPI
- Documentation des choix de modÃ©lisation

---

## ðŸ—ï¸ **PHASE 3 : CRÃ‰ATION DE L'INFRASTRUCTURE DWH**
**ðŸŽ“ CompÃ©tence visÃ©e : C14 - CrÃ©er un entrepÃ´t de donnÃ©es**
**ðŸ“„ Livrables : "Configuration des outils" + "Configuration des accÃ¨s"**

### **Ã‰tape 3.1 : Choix de la solution technique Azure**
- Comparaison Azure Synapse Analytics vs Azure SQL Database
- Justification du choix (coÃ»t, performances, contraintes projet)
- Dimensionnement des ressources (DTU, storage)

### **Ã‰tape 3.2 : DÃ©ploiement de l'infrastructure (IaC)**
- CrÃ©ation du script Terraform pour :
  - Resource Group dÃ©diÃ© DWH
  - Azure SQL Server / Synapse Workspace
  - Bases de donnÃ©es DWH + Datamarts
  - RÃ©seau virtuel et rÃ¨gles firewall
- Automatisation via GitHub Actions

### **Ã‰tape 3.3 : CrÃ©ation des bases de donnÃ©es et schÃ©mas**
- Base principale : `DWH_AUTOMOBILE`
- SchÃ©mas organisÃ©s par datamart :
  - `dbo.DIM_*` (dimensions transverses)
  - `pneumatique.*` (datamart pneus)
  - `mobilite.*` (datamart bornes)
  - `entreprise.*` (datamart sociÃ©tÃ©s auto)

### **Ã‰tape 3.4 : ExÃ©cution des scripts DDL**
- CrÃ©ation de toutes les tables de dimensions (9 tables)
- CrÃ©ation de toutes les tables de faits (3 tables)
- CrÃ©ation des index et contraintes
- Validation de la structure

### **Ã‰tape 3.5 : Configuration de la sÃ©curitÃ© et des accÃ¨s**
**ðŸ“„ Livrable : "Configuration des accÃ¨s aux donnÃ©es"**

#### **AccÃ¨s aux donnÃ©es sources (exigence certification)**
- Configurer les Linked Services Azure Data Factory vers :
  - Azure SQL Database (tables opÃ©rationnelles Produit, Caracteristiques, etc.)
  - Azure Data Lake Gen2 (conteneurs bronze-data, data-gouv, gold-data)
  - Azure Purview (catalogue mÃ©tadonnÃ©es)
- Gestion des identitÃ©s managÃ©es (Managed Identity)
- Stockage sÃ©curisÃ© des credentials (Azure Key Vault)

#### **AccÃ¨s pour les Ã©quipes d'analyse (exigence certification)**
- CrÃ©ation des groupes Azure AD :
  - `DWH_Analystes_BI` : Lecture tous datamarts
  - `DWH_Equipe_Web` : Lecture datamarts Pneumatique + MobilitÃ©
  - `DWH_Data_Engineers` : Full access
  - `DWH_Admins` : PropriÃ©taire base de donnÃ©es
- Attribution des rÃ´les SQL :
  - `db_datareader` pour les analystes
  - `db_datawriter` + `db_datareader` pour les Data Engineers
- Configuration Row-Level Security (RLS) si nÃ©cessaire par rÃ©gion

### **Ã‰tape 3.6 : Configuration de la supervision**
- Azure Monitor : MÃ©triques performances (DTU, stockage, latence)
- Alertes sur Ã©checs de chargement ETL
- Logs d'accÃ¨s et d'audit

---

# ðŸŽ¯ PLAN COMPLET DU PROJET E5 - DATA WAREHOUSE (SUITE)

---

## ðŸ”„ **PHASE 4 : DÃ‰VELOPPEMENT DES PROCESSUS ETL** (SUITE)
**ðŸŽ“ CompÃ©tence visÃ©e : C15 - IntÃ©grer les ETL nÃ©cessaires**

### **Ã‰tape 4.4 : DÃ©veloppement ETL Faits** (SUITE)

#### **ETL 4.4.2 : Chargement FAIT_DISPONIBILITE_BORNE**
- Source : `bornes_irve_hdf_YYYYMMDD.csv` (Data Lake)
- Transformations :
  - Jointure avec DIM_BORNE_RECHARGE
  - Jointure avec DIM_GEOGRAPHIE (via coordonnÃ©es GPS ou code commune)
  - Jointure avec DIM_TEMPS
  - Calcul mÃ©triques : Nombre_Bornes, Puissance_Totale_kW
  - AgrÃ©gation par zone gÃ©ographique
- Mode chargement : Snapshot mensuel (TRUNCATE/INSERT)
- Sortie : `DWH_AUTOMOBILE.mobilite.FAIT_DISPONIBILITE_BORNE`

#### **ETL 4.4.3 : Chargement FAIT_ENTREPRISE_AUTOMOBILE**
- Source : DIM_ENTREPRISE (dÃ©jÃ  chargÃ©e)
- Transformations :
  - Jointure avec DIM_ACTIVITE_NAF
  - Jointure avec DIM_GEOGRAPHIE
  - Jointure avec DIM_TEMPS
  - Filtrage Ã©tablissements actifs uniquement
  - Calcul mÃ©triques : Nombre_Etablissements, Estimation_Salaries (depuis tranche_effectifs)
- Mode chargement : Snapshot mensuel
- Sortie : `DWH_AUTOMOBILE.entreprise.FAIT_ENTREPRISE_AUTOMOBILE`

### **Ã‰tape 4.5 : Programmation des traitements de nettoyage**
**ðŸ“„ Livrable : "Programmation des traitements appliquÃ©s aux donnÃ©es"**

- **Nettoyage SIRENE** : Suppression valeurs NULL critiques, normalisation adresses, validation SIRET
- **Nettoyage NAF** : Parsing format XLS, suppression lignes vides, validation codes
- **Nettoyage Bornes** : Validation coordonnÃ©es GPS, suppression doublons, standardisation noms opÃ©rateurs
- **Nettoyage Communes** : Validation codes INSEE, cohÃ©rence population/superficie
- **Nettoyage Pneus** : Validation prix (>0), dimensions cohÃ©rentes, notes format correct

### **Ã‰tape 4.6 : Configuration des zones de sortie ETL**
**ðŸ“„ Livrable : "Configuration des zones de sorties des ETL"**

| Zone | Localisation | Type donnÃ©es | RÃ´le |
|------|--------------|--------------|------|
| **Bronze** | Data Lake `bronze-data` | DonnÃ©es brutes | Stockage initial sans transformation |
| **Silver** | Data Lake `gold-data/silver` | DonnÃ©es nettoyÃ©es | AprÃ¨s nettoyage et validation |
| **Gold** | Data Lake `gold-data/gold` | DonnÃ©es enrichies | AprÃ¨s transformations mÃ©tier |
| **DWH Tables** | Azure SQL `DWH_AUTOMOBILE` | Tables dimensionnelles | Zone finale consommation |

### **Ã‰tape 4.7 : Orchestration et planification**
- CrÃ©ation pipelines Azure Data Factory :
  - **Pipeline_Dimensions** : Chargement quotidien dimensions (prioritÃ© 1)
  - **Pipeline_Faits_Pneus** : Chargement quotidien fait prix (prioritÃ© 2)
  - **Pipeline_Faits_Bornes** : Chargement mensuel (jour 1 du mois)
  - **Pipeline_Faits_Entreprises** : Chargement mensuel (jour 5 du mois)
- Configuration triggers temporels (schedules)
- Gestion des dÃ©pendances entre pipelines
- MÃ©canisme de retry en cas d'Ã©chec

### **Ã‰tape 4.8 : Gestion des erreurs et logging**
- Tables de contrÃ´le ETL :
  - `ETL_LOG_EXECUTION` : Historique exÃ©cutions (date, durÃ©e, statut, lignes traitÃ©es)
  - `ETL_LOG_ERREURS` : DÃ©tail des erreurs (timestamp, pipeline, message, ligne source)
- Notifications email en cas d'Ã©chec
- Dashboard monitoring temps rÃ©el (Azure Monitor)

---

## âœ… **PHASE 5 : TESTS ET VALIDATION**
**ðŸŽ“ CompÃ©tence visÃ©e : C15 (qualitÃ© des donnÃ©es) + Exigence certification "organiser la phase de test"**
**ðŸ“„ Livrable : "Plan de test" + "Rapport de tests"**

### **Ã‰tape 5.1 : DÃ©finition du plan de test**
- Tests unitaires par ETL
- Tests d'intÃ©gration end-to-end
- Tests de performance
- Tests de qualitÃ© des donnÃ©es
- Tests de sÃ©curitÃ©/accÃ¨s

### **Ã‰tape 5.2 : Tests unitaires des transformations**
- Validation chaque transformation ETL individuellement
- Jeux de donnÃ©es de test contrÃ´lÃ©s
- VÃ©rification des rÃ¨gles mÃ©tier (ex: prix > 0, codes NAF valides)

### **Ã‰tape 5.3 : Tests d'intÃ©gritÃ© rÃ©fÃ©rentielle**
- VÃ©rification clÃ©s Ã©trangÃ¨res (Faits â†’ Dimensions)
- Absence de valeurs orphelines
- Contraintes NOT NULL respectÃ©es
- UnicitÃ© des clÃ©s de substitution

### **Ã‰tape 5.4 : Tests de volumÃ©trie**
- Comptage lignes source vs destination
- VÃ©rification cohÃ©rence agrÃ©gats
- DÃ©tection de pertes de donnÃ©es
- Exemple : `COUNT(*) FROM Produit` = `COUNT(*) FROM FAIT_PRIX_PNEU WHERE Date = TODAY`

### **Ã‰tape 5.5 : Tests de qualitÃ© des donnÃ©es**
- DÃ©tection valeurs NULL anormales
- DÃ©tection doublons
- Validation formats (dates, codes postaux, emails)
- CohÃ©rence des donnÃ©es (ex: population > 0, superficie > 0)

### **Ã‰tape 5.6 : Tests de performance**
- Temps de chargement ETL (objectif < 30 min pour chargement quotidien)
- Temps de rÃ©ponse requÃªtes analytiques (objectif < 5 sec pour requÃªtes BI)
- Optimisation index si nÃ©cessaire

### **Ã‰tape 5.7 : Tests de sÃ©curitÃ©**
- VÃ©rification accÃ¨s par groupe AD
- Test blocage accÃ¨s non autorisÃ©s
- Validation RLS (Row-Level Security) si implÃ©mentÃ©

### **Ã‰tape 5.8 : Tests de bout en bout (E2E)**
- Simulation chargement complet : Source â†’ Bronze â†’ Silver â†’ Gold â†’ DWH
- Validation donnÃ©es accessibles depuis Power BI / Site Web
- Test requÃªtes mÃ©tier rÃ©elles

### **Ã‰tape 5.9 : Documentation des rÃ©sultats de test**
- Tableau de synthÃ¨se : Tests passÃ©s/Ã©chouÃ©s
- Actions correctives pour tests Ã©chouÃ©s
- Validation par responsable mÃ©tier

---

## ðŸ“š **PHASE 6 : DOCUMENTATION TECHNIQUE**
**ðŸŽ“ CompÃ©tence visÃ©e : C13, C14, C15 (toutes) + Exigence certification "rÃ©diger la documentation technique"**
**ðŸ“„ Livrable : "Documentation technique complÃ¨te du DWH"**

### **Ã‰tape 6.1 : RÃ©daction du dictionnaire de donnÃ©es**
- Description dÃ©taillÃ©e de toutes les tables (Dimensions + Faits)
- Pour chaque colonne : Nom, Type, Longueur, Nullable, Description mÃ©tier, Exemple
- Glossaire des termes mÃ©tier

### **Ã‰tape 6.2 : Documentation des modÃ¨les de donnÃ©es**
- SchÃ©mas visuels (MLD/MPD) au format image/PDF
- LÃ©gende des conventions (clÃ©s, relations, cardinalitÃ©s)
- Justification des choix de modÃ©lisation

### **Ã‰tape 6.3 : Documentation des flux ETL**
- Diagramme de flux pour chaque pipeline
- Description Ã©tape par Ã©tape des transformations
- RÃ¨gles de gestion appliquÃ©es
- FrÃ©quence d'exÃ©cution et fenÃªtres de traitement

### **Ã‰tape 6.4 : Guide d'utilisation pour les analystes**
- Comment se connecter au DWH (Power BI, Excel, Python)
- RequÃªtes SQL types pour chaque cas d'usage mÃ©tier
- Exemples de jointures entre Faits et Dimensions
- Bonnes pratiques de requÃªtage

### **Ã‰tape 6.5 : Documentation d'exploitation**
- ProcÃ©dures de supervision (Azure Monitor, logs)
- ProcÃ©dure de redÃ©marrage en cas d'Ã©chec ETL
- ProcÃ©dure de restauration (backups)
- Contacts support et escalade

### **Ã‰tape 6.6 : Documentation de sÃ©curitÃ©**
- Matrice des accÃ¨s (rÃ´les, groupes AD, permissions)
- ProcÃ©dure d'ajout d'un nouvel utilisateur
- Politique de gestion des credentials (Key Vault)

### **Ã‰tape 6.7 : SchÃ©ma d'architecture technique global**
- Diagramme complet : Sources â†’ Data Lake â†’ ETL â†’ DWH â†’ Consommateurs
- Technologies utilisÃ©es Ã  chaque niveau
- Flux de donnÃ©es et dÃ©pendances

---

## ðŸ” **PHASE 7 : RETOUR D'EXPÃ‰RIENCE**
**ðŸŽ“ CompÃ©tence visÃ©e : C14 + Exigence certification "formaliser un retour d'expÃ©rience des outils techniques"**
**ðŸ“„ Livrable : "Retour d'expÃ©rience technique"**

### **Ã‰tape 7.1 : Analyse des choix technologiques**

#### **Azure SQL Database vs Azure Synapse Analytics**
- **Choix retenu** : [Ã€ complÃ©ter selon ton choix]
- **CohÃ©rence avec contraintes projet** : Budget, volumÃ©trie, complexitÃ© requÃªtes
- **Avantages** : FacilitÃ© dÃ©ploiement, coÃ»t, intÃ©gration Azure, performances
- **DifficultÃ©s rencontrÃ©es** : Limitations DTU, temps chargement gros volumes, courbe apprentissage

#### **Azure Data Factory**
- **CohÃ©rence** : Orchestration native Azure, intÃ©gration Data Lake/SQL
- **Avantages** : Interface visuelle, triggers, monitoring intÃ©grÃ©, pas de serveur Ã  gÃ©rer
- **DifficultÃ©s** : Debuggage pipelines complexes, gestion erreurs, coÃ»t calcul

#### **Azure Databricks (pour SIRENE)**
- **CohÃ©rence** : Traitement distribuÃ© Spark nÃ©cessaire pour 42M lignes
- **Avantages** : Performance sur gros volumes, langage Python/SQL familier
- **DifficultÃ©s** : CoÃ»t cluster, configuration rÃ©seau, optimisation partitions Parquet

#### **Terraform (IaC)**
- **CohÃ©rence** : ReproductibilitÃ©, versioning, automatisation CI/CD
- **Avantages** : DÃ©ploiement rapide, documentation as code, rollback facile
- **DifficultÃ©s** : Syntaxe HCL, gestion state file, permissions Azure

### **Ã‰tape 7.2 : Analyse des performances obtenues**
- Temps de chargement ETL vs objectifs
- Temps de rÃ©ponse requÃªtes vs SLA
- Optimisations appliquÃ©es (index, partitionnement)
- VolumÃ©trie traitÃ©e vs capacitÃ© infrastructure

### **Ã‰tape 7.3 : Identification des points d'amÃ©lioration**
- Automatisation tests qualitÃ© donnÃ©es
- Mise en place CDC (Change Data Capture) pour Ã©viter full load
- ImplÃ©mentation data lineage complet (Azure Purview)
- Migration vers architecture Lambda (temps rÃ©el + batch)

### **Ã‰tape 7.4 : Recommandations pour Ã©volutions futures**
- Ajout nouvelles sources (API temps rÃ©el constructeurs auto)
- CrÃ©ation nouveaux datamarts (Assurance auto, Financement)
- ImplÃ©mentation Machine Learning (prÃ©diction prix pneus)
- Migration Progressive vers Synapse si volumes explosent

### **Ã‰tape 7.5 : Bilan compÃ©tences acquises**
- ModÃ©lisation dimensionnelle (schÃ©ma Ã©toile, SCD Type 2)
- MaÃ®trise Ã©cosystÃ¨me Azure Data (ADF, Databricks, SQL, Data Lake)
- Optimisation performances requÃªtes analytiques
- Gestion projet Data Engineering end-to-end

---

## ðŸ“¦ **SYNTHÃˆSE DES LIVRABLES POUR LA CERTIFICATION**

| **Exigence certification** | **Livrable** | **Phase** | **CompÃ©tence** |
|----------------------------|--------------|-----------|----------------|
| Produire liste des donnÃ©es nÃ©cessaires | Document inventaire sources + besoins mÃ©tier | Phase 1 | C13 |
| ModÃ©lisations logiques et physiques | MLD + MPD + Scripts DDL | Phase 2 | C13 |
| Configurer outils DWH | Scripts Terraform + Config Azure | Phase 3 | C14 |
| Configurer accÃ¨s Ã©quipes analyse | Matrice accÃ¨s AD + RÃ´les SQL | Phase 3 | C14 |
| Configurer accÃ¨s sources | Linked Services ADF + Key Vault | Phase 3 | C14 |
| Organiser phase de test | Plan de test + Rapport rÃ©sultats | Phase 5 | C15 |
| RÃ©diger documentation technique | Documentation complÃ¨te DWH | Phase 6 | C13/C14/C15 |
| Formaliser retour d'expÃ©rience | REX outils techniques | Phase 7 | C14 |
| IntÃ©grer sources aux ETL | Pipelines ADF/Databricks | Phase 4 | C15 |
| Configurer zones sortie ETL | Architecture Bronze/Silver/Gold | Phase 4 | C15 |
| Programmer traitements donnÃ©es | Code Python/SQL transformations | Phase 4 | C15 |

---

